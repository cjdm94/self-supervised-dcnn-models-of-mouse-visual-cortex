{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We want to run PCA on the raw STL10 images, and on the corresponding SimCLR representations of those images\n",
    "### We expect that for the raw images, more PCs will be required to explain a high proportion of the variance\n",
    "### We expect that for the SimCLR representations, we will see a high proportion of the variance explained by fewer PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    # $pip install --quiet pytorch-lightning>=1.4\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"--quiet\", \"pytorch-lightning>=1.4\"])\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
    "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import STL10\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    # $pip install --quiet pytorch-lightning>=1.4\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"--quiet\", \"pytorch-lightning>=1.4\"])\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "DATASET_PATH = \"../data\"\n",
    "MODEL_CHECKPOINT_PATH = \"../models/tutorial17/SimCLR.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_stl10_images(dataset):\n",
    "    \"\"\"\n",
    "    PCA operates on a 2D matrix, where each row is a data sample (an image) and each column is a feature (pixel value)\n",
    "    First, flatten each image into a vector\n",
    "    Then stack all image vectors into a matrix X of shape N x D, where N is num images, and D is num pixels per image (features)\n",
    "    D = the number of features per vector = 96 x 96 pixels x 3 (RGB channels) = 27648 features per image\n",
    "    N = 5000 images\n",
    "\n",
    "    STL10 image:             (96, 96, 3)\n",
    "    Tensor:                  (3, 96, 96)\n",
    "    Data stack (all images): (5000, 3, 96, 96)\n",
    "    Matrix X (flattened):    (5000, 27648)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all 5000 images as a single batch into memory\n",
    "    data_loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    images, labels = next(iter(data_loader))\n",
    "\n",
    "    # Reshapes (flattens) each image in the batch into a 1D vector \n",
    "    # (num_images, channels, height, width) -> (num_images, num_pixels)\n",
    "    num_images, channels, height, width = images.shape\n",
    "    flattened_images = images.view(num_images, -1)\n",
    "\n",
    "    return data.TensorDataset(flattened_images, labels)\n",
    "\n",
    "class SimCLR(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        \n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        \n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "@torch.no_grad()\n",
    "def prepare_features_simclr_representations(model, dataset):\n",
    "    \"\"\"\n",
    "    This removes the projection head of the SimCLR model and uses the base encoder to extract feature representations \n",
    "    for each image in the (in this case STL10) dataset.\n",
    "\n",
    "    The projection head is the \"small neural network projection head g(·) that maps representations to the space where contrastive loss is applied\".\n",
    "    The authors of the SimCLR paper note that they \"throw away the projection head g(·) and use encoder f(·) and representation h for downstream tasks.\"\n",
    "    \n",
    "    \"A nonlinear projection head improves the representation quality of the layer before it\" but \n",
    "    \"the hidden layer before the projection head is a better representation than the layer after\".\n",
    "    \"\"\"\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    return data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained SimCLR model\n",
    "model = SimCLR.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run PCA on the raw STL10 images, and on the corresponding SimCLR representations of those images\n",
    "num_components = 150\n",
    "\n",
    "stl10_dataset = STL10(root=DATASET_PATH, split='train', download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Prepare the raw STL10 images for PCA\n",
    "stl10_prepared = prepare_features_stl10_images(stl10_dataset)\n",
    "stl10_feats, stl10_labels = stl10_prepared.tensors\n",
    "\n",
    "# Run PCA on the raw STL10 images\n",
    "pca_stl10 = PCA(n_components=num_components)\n",
    "pca_stl10.fit(stl10_feats.numpy())\n",
    "explained_variance_stl10 = pca_stl10.explained_variance_ratio_\n",
    "cumulative_variance_stl10 = np.cumsum(explained_variance_stl10)\n",
    "\n",
    "# Extract SimCLR representations for the same images; prepare representations for PCA\n",
    "simclr_prepared = prepare_features_simclr_representations(model, stl10_dataset)\n",
    "simclr_feats, simclr_labels = simclr_prepared.tensors\n",
    "\n",
    "print(\"First 10 labels in STL10 features:\", stl10_labels[:10])\n",
    "print(\"First 10 labels in SimCLR features:\", stl10_labels[:10])\n",
    "\n",
    "# Run PCA on the SimCLR representations\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_feats.numpy())\n",
    "explained_variance_simclr = pca_simclr.explained_variance_ratio_\n",
    "cumulative_variance_simclr = np.cumsum(explained_variance_simclr)\n",
    "\n",
    "# Plot results\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_variance_stl10, label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, cumulative_variance_simclr, label=\"SimCLR Representations\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's try PCA on earlier layers of the base encoder from the SimCLR mode\n",
    "\n",
    "class SimCLRWithIntermediateLayerOutputs(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    @todo I adapted these from the SimCLR class from the 001_test_sim_clr.ipynb tutorial notebook\n",
    "    There it is used for training and feature extraction\n",
    "    We can remove the training logic - all we need is the pretrained base encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        \n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        \n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "# Function to register hooks and capture outputs from intermediate layers\n",
    "def register_hooks(model, layers):\n",
    "    features = {}\n",
    "\n",
    "    def hook(module, input, output, layer_name):\n",
    "        features[layer_name] = output.detach()\n",
    "\n",
    "    for layer_name in layers:\n",
    "        layer = dict([*model.named_modules()])[layer_name]\n",
    "        layer.register_forward_hook(lambda module, input, output, layer_name=layer_name: hook(module, input, output, layer_name))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Modified function to prepare features with intermediate layer outputs\n",
    "@torch.no_grad()\n",
    "def prepare_features_simclr_representations_multi_layer(model, dataset, layers_to_capture):\n",
    "    # Prepare model and register hooks\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Register hooks to capture specific intermediate layers\n",
    "    features = register_hooks(network, layers_to_capture)\n",
    "    \n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels, intermediate_features = [], [], {layer: [] for layer in layers_to_capture}\n",
    "    \n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "        \n",
    "        # Collect intermediate layer outputs\n",
    "        for layer in layers_to_capture:\n",
    "            # Final linear layer outputs a 2d tensor; but intermediate layers don't, so we flatten them ready for PCA \n",
    "            layer_output_flattened = features[layer].view(features[layer].size(0), -1) \n",
    "            intermediate_features[layer].append(layer_output_flattened.cpu())\n",
    "    \n",
    "    # Concatenate results for each layer\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    intermediate_features = {layer: torch.cat(intermediate_features[layer], dim=0) for layer in layers_to_capture}\n",
    "    \n",
    "    return data.TensorDataset(feats, labels), intermediate_features\n",
    "\n",
    "# Load the pretrained SimCLR model\n",
    "model = SimCLRWithIntermediateLayerOutputs.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model.eval()\n",
    "\n",
    "layers_to_capture = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "# Extract SimCLR representations and intermediate features\n",
    "simclr_prepared, intermediate_features = prepare_features_simclr_representations_multi_layer(model, stl10_dataset, layers_to_capture)\n",
    "simclr_feats, simclr_labels = simclr_prepared.tensors\n",
    "layer1_feats = intermediate_features['layer1']\n",
    "layer2_feats = intermediate_features['layer2']\n",
    "layer4_feats = intermediate_features['layer4']\n",
    "\n",
    "# Layer 1 features shape:     torch.Size([5000, 36864])\n",
    "# Layer 2 features shape:     torch.Size([5000, 18432])\n",
    "# Layer 4 features shape:     torch.Size([5000, 4608])])\n",
    "# Final Layer features shape: torch.Size([5000, 512]\n",
    "print(\"Layer 1 features shape:\", layer1_feats.shape) \n",
    "print(\"Layer 2 features shape:\", layer2_feats.shape) \n",
    "print(\"Layer 4 features shape:\", layer4_feats.shape)\n",
    "print(\"Final Layer features shape:\", simclr_feats.shape)\n",
    "\n",
    "num_components = 150\n",
    "\n",
    "# Run PCA on the SimCLR layer 1\n",
    "pca_simclr_layer1 = PCA(n_components=num_components)\n",
    "pca_simclr_layer1.fit(layer1_feats.numpy())\n",
    "explained_variance_simclr_layer1 = pca_simclr_layer1.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer1 = np.cumsum(explained_variance_simclr_layer1)\n",
    "\n",
    "# Run PCA on the SimCLR layer 2\n",
    "pca_simclr_layer2 = PCA(n_components=num_components)\n",
    "pca_simclr_layer2.fit(layer2_feats.numpy())\n",
    "explained_variance_simclr_layer2 = pca_simclr_layer2.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer2 = np.cumsum(explained_variance_simclr_layer2)\n",
    "\n",
    "# Run PCA on the SimCLR layer 4\n",
    "pca_simclr_layer4 = PCA(n_components=num_components)\n",
    "pca_simclr_layer4.fit(layer4_feats.numpy())\n",
    "explained_variance_simclr_layer4 = pca_simclr_layer4.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer4 = np.cumsum(explained_variance_simclr_layer4)\n",
    "\n",
    "# Run PCA on final linear layer\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_feats.numpy())\n",
    "explained_variance_simclr = pca_simclr.explained_variance_ratio_\n",
    "cumulative_variance_simclr = np.cumsum(explained_variance_simclr)\n",
    "\n",
    "# Plot results\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_variance_stl10, label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer1, label=\"SimCLR Layer 1\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer2, label=\"SimCLR Layer 2\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer4, label=\"SimCLR Layer 4\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr, label=\"SimCLR Final Layer\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
