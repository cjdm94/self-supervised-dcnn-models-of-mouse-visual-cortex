{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We want to run PCA on the raw STL10 images, and on the corresponding SimCLR representations of those images\n",
    "### We expect that for the raw images, more PCs will be required to explain a high proportion of the variance\n",
    "### We expect that for the SimCLR representations, we will see a high proportion of the variance explained by fewer PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/21m3vmjd7c1_75f4nxmg1k480000gn/T/ipykernel_86496/1944442167.py:10: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Number of workers: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    # $pip install --quiet pytorch-lightning>=1.4\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"--quiet\", \"pytorch-lightning>=1.4\"])\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
    "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import STL10\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    # $pip install --quiet pytorch-lightning>=1.4\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"--quiet\", \"pytorch-lightning>=1.4\"])\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "DATASET_PATH = \"../../data\"\n",
    "MODEL_CHECKPOINT_PATH = \"../../models/tutorial17/SimCLR.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_stl10_images(dataset):\n",
    "    \"\"\"\n",
    "    PCA operates on a 2D matrix, where each row is a data sample (an image) and each column is a feature (pixel value)\n",
    "    First, flatten each image into a vector\n",
    "    Then stack all image vectors into a matrix X of shape N x D, where N is num images, and D is num pixels per image (features)\n",
    "    D = the number of features per vector = 96 x 96 pixels x 3 (RGB channels) = 27648 features per image\n",
    "    N = 5000 images\n",
    "\n",
    "    STL10 image:             (96, 96, 3)\n",
    "    Tensor:                  (3, 96, 96)\n",
    "    Data stack (all images): (5000, 3, 96, 96)\n",
    "    Matrix X (flattened):    (5000, 27648)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all 5000 images as a single batch into memory\n",
    "    # DataLoader is used to load data in batches, but we want to load all data at once\n",
    "    # iter(data_loader) converts it to an iterator\n",
    "    # next(...) gets the first (and only) batch from the iterator\n",
    "    data_loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    images, labels = next(iter(data_loader))\n",
    "\n",
    "    # Reshapes (flattens) each image in the batch into a 1D vector \n",
    "    # images.view(num_images, -1) -> \"Make the first dimension num_images and calculate whatever is left for the second dimension.\"\n",
    "    # (num_images, channels, height, width) -> (num_images, num_pixels)\n",
    "    num_images, channels, height, width = images.shape\n",
    "    flattened_images = images.view(num_images, -1)\n",
    "\n",
    "    return data.TensorDataset(flattened_images, labels)\n",
    "\n",
    "class SimCLR(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    @todo I adapted these from the SimCLR class from the 001_test_sim_clr.ipynb tutorial notebook\n",
    "    There it is used for training and feature extraction\n",
    "    We can remove the training logic - all we need is the pretrained base encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        \"\"\"\n",
    "        PyTorch Lightning's load_from_checkpoint (called in cells below) handles hyperparameter loading automatically,\n",
    "        just grabs them from the checkpoint itself so we don't have to pass them when we initialise SimCLR class, or call \n",
    "        load_from_checkpoint\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters() # \n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        \n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        \n",
    "        # We don't actually need this as we're just extracting features (from the base encoder)\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "@torch.no_grad()\n",
    "def prepare_features_simclr_representations(model, dataset):\n",
    "    \"\"\"\n",
    "    This removes the projection head of the SimCLR model and uses the base encoder to extract feature representations \n",
    "    for each image in the (in this case STL10) dataset.\n",
    "\n",
    "    The projection head is the \"small neural network projection head g(·) that maps representations to the space where contrastive loss is applied\".\n",
    "    The authors of the SimCLR paper note that they \"throw away the projection head g(·) and use encoder f(·) and representation h for downstream tasks.\"\n",
    "    \n",
    "    \"A nonlinear projection head improves the representation quality of the layer before it\" but \n",
    "    \"the hidden layer before the projection head is a better representation than the layer after\".\n",
    "    \"\"\"\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.) - Identity just returns its input, performs no operation\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        feats.append(batch_feats.detach().cpu()) # @todo: what are detatch() and cpu() doing here?\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    # @todo what is a Tensor?\n",
    "    return data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/callummessiter/workspace/msc-neuro/research-project/notebooks/002_pca/../models/tutorial17/SimCLR.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load pretrained SimCLR model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# \"evaluation mode\" gives consistent and stable feature representations \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# - cos it disables \"dropout\" (where during training neurons are randomly set to zero to prevent overfitting) \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# and \"fixes batch normalization statistics\".\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# So eval mode makes the outputs suitable for analysis with PCA (but I don't know what any of this stuff is, so need to read)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimCLR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_CHECKPOINT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1582\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1501\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \n\u001b[1;32m   1581\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:63\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m map_location \u001b[38;5;241m=\u001b[39m map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     66\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     67\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py:59\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     55\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     61\u001b[0m         f,\n\u001b[1;32m     62\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/fsspec/spec.py:1301\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1301\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1310\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/fsspec/implementations/local.py:195\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/fsspec/implementations/local.py:359\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/msc-neuro/research-project/myenv/lib/python3.11/site-packages/fsspec/implementations/local.py:364\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    366\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/callummessiter/workspace/msc-neuro/research-project/notebooks/002_pca/../models/tutorial17/SimCLR.ckpt'"
     ]
    }
   ],
   "source": [
    "# load pretrained SimCLR model\n",
    "# \"evaluation mode\" gives consistent and stable feature representations \n",
    "# - cos it disables \"dropout\" (where during training neurons are randomly set to zero to prevent overfitting) \n",
    "# and \"fixes batch normalization statistics\".\n",
    "# So eval mode makes the outputs suitable for analysis with PCA (but I don't know what any of this stuff is, so need to read)\n",
    "model = SimCLR.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run PCA on the raw STL10 images, and on the corresponding SimCLR representations of those images\n",
    "num_components = 500\n",
    "\n",
    "stl10_dataset = STL10(root=DATASET_PATH, split='train', download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Prepare the raw STL10 images for PCA\n",
    "stl10_prepared = prepare_features_stl10_images(stl10_dataset)\n",
    "stl10_feats, stl10_labels = stl10_prepared.tensors\n",
    "\n",
    "# Run PCA on the raw STL10 images\n",
    "pca_stl10 = PCA(n_components=num_components)\n",
    "pca_stl10.fit(stl10_feats.numpy())\n",
    "explained_variance_stl10 = pca_stl10.explained_variance_ratio_\n",
    "cumulative_variance_stl10 = np.cumsum(explained_variance_stl10)\n",
    "\n",
    "# Extract SimCLR representations for the same images; prepare representations for PCA\n",
    "simclr_prepared = prepare_features_simclr_representations(model, stl10_dataset)\n",
    "simclr_feats, simclr_labels = simclr_prepared.tensors\n",
    "\n",
    "print(\"First 10 labels in STL10 features:\", stl10_labels[:10])\n",
    "print(\"First 10 labels in SimCLR features:\", stl10_labels[:10])\n",
    "\n",
    "# Run PCA on the SimCLR representations\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_feats.numpy())\n",
    "explained_variance_simclr = pca_simclr.explained_variance_ratio_\n",
    "cumulative_variance_simclr = np.cumsum(explained_variance_simclr)\n",
    "\n",
    "# Plot results\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_variance_stl10, label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, cumulative_variance_simclr, label=\"SimCLR Representations\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's try PCA on earlier layers of the base encoder from the SimCLR mode\n",
    "\n",
    "class SimCLRWithIntermediateLayerOutputs(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        \n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        \n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "# Function to register hooks and capture outputs from intermediate layers\n",
    "def register_hooks(model, layers):\n",
    "    features = {}\n",
    "\n",
    "    def hook(module, input, output, layer_name):\n",
    "        features[layer_name] = output.detach()\n",
    "\n",
    "    for layer_name in layers:\n",
    "        layer = dict([*model.named_modules()])[layer_name]\n",
    "        layer.register_forward_hook(lambda module, input, output, layer_name=layer_name: hook(module, input, output, layer_name))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Modified function to prepare features with intermediate layer outputs\n",
    "@torch.no_grad()\n",
    "def prepare_features_simclr_representations_multi_layer(model, dataset, layers_to_capture):\n",
    "    # Prepare model and register hooks\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Register hooks to capture specific intermediate layers\n",
    "    features = register_hooks(network, layers_to_capture)\n",
    "    \n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels, intermediate_features = [], [], {layer: [] for layer in layers_to_capture}\n",
    "    \n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "        \n",
    "        # Collect intermediate layer outputs\n",
    "        for layer in layers_to_capture:\n",
    "            # Final linear layer outputs a 2d tensor; but intermediate layers don't, so we flatten them ready for PCA \n",
    "            layer_output_flattened = features[layer].view(features[layer].size(0), -1) \n",
    "            intermediate_features[layer].append(layer_output_flattened.cpu())\n",
    "    \n",
    "    # Concatenate results for each layer\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    intermediate_features = {layer: torch.cat(intermediate_features[layer], dim=0) for layer in layers_to_capture}\n",
    "    \n",
    "    return data.TensorDataset(feats, labels), intermediate_features\n",
    "\n",
    "# Load the pretrained SimCLR model\n",
    "model = SimCLRWithIntermediateLayerOutputs.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model.eval()\n",
    "\n",
    "layers_to_capture = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "# Extract SimCLR representations and intermediate features\n",
    "simclr_prepared, intermediate_features = prepare_features_simclr_representations_multi_layer(model, stl10_dataset, layers_to_capture)\n",
    "simclr_feats, simclr_labels = simclr_prepared.tensors\n",
    "layer1_feats = intermediate_features['layer1']\n",
    "layer2_feats = intermediate_features['layer2']\n",
    "layer4_feats = intermediate_features['layer4']\n",
    "\n",
    "# Layer 1 features shape:     torch.Size([5000, 36864])\n",
    "# Layer 2 features shape:     torch.Size([5000, 18432])\n",
    "# Layer 4 features shape:     torch.Size([5000, 4608])])\n",
    "# Final Layer features shape: torch.Size([5000, 512])\n",
    "print(\"Layer 1 features shape:\", layer1_feats.shape) \n",
    "print(\"Layer 2 features shape:\", layer2_feats.shape) \n",
    "print(\"Layer 4 features shape:\", layer4_feats.shape)\n",
    "print(\"Final Layer features shape:\", simclr_feats.shape)\n",
    "\n",
    "num_components = 500\n",
    "\n",
    "# Run PCA on the SimCLR layer 1\n",
    "pca_simclr_layer1 = PCA(n_components=num_components)\n",
    "pca_simclr_layer1.fit(layer1_feats.numpy())\n",
    "explained_variance_simclr_layer1 = pca_simclr_layer1.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer1 = np.cumsum(explained_variance_simclr_layer1)\n",
    "\n",
    "# Run PCA on the SimCLR layer 2\n",
    "pca_simclr_layer2 = PCA(n_components=num_components)\n",
    "pca_simclr_layer2.fit(layer2_feats.numpy())\n",
    "explained_variance_simclr_layer2 = pca_simclr_layer2.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer2 = np.cumsum(explained_variance_simclr_layer2)\n",
    "\n",
    "# Run PCA on the SimCLR layer 4\n",
    "pca_simclr_layer4 = PCA(n_components=num_components)\n",
    "pca_simclr_layer4.fit(layer4_feats.numpy())\n",
    "explained_variance_simclr_layer4 = pca_simclr_layer4.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer4 = np.cumsum(explained_variance_simclr_layer4)\n",
    "\n",
    "# Run PCA on final linear layer\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_feats.numpy())\n",
    "explained_variance_simclr = pca_simclr.explained_variance_ratio_\n",
    "cumulative_variance_simclr = np.cumsum(explained_variance_simclr)\n",
    "\n",
    "# Plot cumulative explained variance against number of principal components\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_variance_stl10, label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer1, label=\"SimCLR Layer 1\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer2, label=\"SimCLR Layer 2\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer4, label=\"SimCLR Layer 4\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr, label=\"SimCLR Final Layer\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot explained variance (log) against number of principal components (log)\n",
    "plot_components = np.log10(range(1, num_components + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, np.log10(explained_variance_stl10), label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr_layer1), label=\"SimCLR Layer 1\", marker='x')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr_layer2), label=\"SimCLR Layer 2\", marker='x')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr_layer4), label=\"SimCLR Layer 4\", marker='x')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr), label=\"SimCLR Final Layer\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "### The initial PCs for the raw images capture a lot of simple pixel-level variance - raw images explain more variance vs. SimCLR final layer\n",
    "### After a certain number of PCs (~40), SimCLR explains a higher level of the variance vs. the raw images\n",
    "### For SimCLR, each principal component captures more complex, high-level features (more meaningful variance rather than noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SimCLR: Cross-validate the findings from the PCA analysis by plotting #PCs for e.g. 4000 images, and plot explained variance for the other 1000\n",
    "\n",
    "# Run PCA on \"training\" subset of the representations\n",
    "simclr_train, simclr_test = torch.utils.data.random_split(simclr_feats, [4000, 1000])\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_train)\n",
    "explained_var_simclr_train = pca_simclr.explained_variance_ratio_\n",
    "\n",
    "# Fit the PCA model on the test set \n",
    "simclr_test_transformed = pca_simclr.transform(simclr_test)\n",
    "explained_var_simclr_test = np.var(simclr_test_transformed, axis=0) / np.sum(np.var(simclr_test, axis=0))\n",
    "\n",
    "# Compute cumulative explained variances\n",
    "cumulative_variance_train = np.cumsum(explained_var_simclr_train)\n",
    "cumulative_variance_test = np.cumsum(explained_var_simclr_test)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_train) + 1), cumulative_variance_train, label=\"Training Set\", marker='o')\n",
    "plt.plot(range(1, len(cumulative_variance_test) + 1), cumulative_variance_test, label=\"Test Set\", marker='x')\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"SimCLR final layer: Cross-Validation of PCA Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Raw images: cross-validate the findings from the PCA analysis by plotting #PCs for e.g. 4000 images, and plot explained variance for the other 1000\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Run PCA on \"training\" subset of the representations\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m stl10_train, stl10_test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(stl10_feats, [\u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m1000\u001b[39m])\n\u001b[1;32m      5\u001b[0m pca_stl10 \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mnum_components)\n\u001b[1;32m      6\u001b[0m pca_stl10\u001b[38;5;241m.\u001b[39mfit(stl10_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "### Raw images: cross-validate the findings from the PCA analysis by plotting #PCs for e.g. 4000 images, and plot explained variance for the other 1000\n",
    "\n",
    "# Run PCA on \"training\" subset of the representations\n",
    "stl10_train, stl10_test = torch.utils.data.random_split(stl10_feats, [4000, 1000])\n",
    "pca_stl10 = PCA(n_components=num_components)\n",
    "pca_stl10.fit(stl10_train)\n",
    "explained_var_stl10_train = pca_stl10.explained_variance_ratio_\n",
    "\n",
    "# Fit the PCA model on the test set \n",
    "stl10_test_transformed = pca_stl10.transform(stl10_test)\n",
    "explained_var_stl10_test = np.var(stl10_test_transformed, axis=0) / np.sum(np.var(stl10_test, axis=0))\n",
    "\n",
    "# Compute cumulative explained variances\n",
    "cumulative_variance_train = np.cumsum(explained_var_stl10_train)\n",
    "cumulative_variance_test = np.cumsum(explained_var_stl10_test)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_train) + 1), cumulative_variance_train, label=\"Training Set\", marker='o')\n",
    "plt.plot(range(1, len(cumulative_variance_test) + 1), cumulative_variance_test, label=\"Test Set\", marker='x')\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Raw STL10: Cross-Validation of PCA Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
