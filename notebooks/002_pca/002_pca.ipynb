{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We want to run PCA on the raw STL10 images, and on the corresponding SimCLR representations of those images\n",
    "### We expect that for the raw images, more PCs will be required to explain a high proportion of the variance\n",
    "### We expect that for the SimCLR representations, we will see a high proportion of the variance explained by fewer PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    # $pip install --quiet pytorch-lightning>=1.4\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"--quiet\", \"pytorch-lightning>=1.4\"])\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
    "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import STL10\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    # $pip install --quiet pytorch-lightning>=1.4\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"--quiet\", \"pytorch-lightning>=1.4\"])\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "DATASET_PATH = \"../../data\"\n",
    "MODEL_CHECKPOINT_PATH = \"../../models/tutorial17/SimCLR.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_stl10_images(dataset):\n",
    "    \"\"\"\n",
    "    PCA operates on a 2D matrix, where each row is a data sample (an image) and each column is a feature (pixel value)\n",
    "    First, flatten each image into a vector\n",
    "    Then stack all image vectors into a matrix X of shape N x D, where N is num images, and D is num pixels per image (features)\n",
    "    D = the number of features per vector = 96 x 96 pixels x 3 (RGB channels) = 27648 features per image\n",
    "    N = 5000 images\n",
    "\n",
    "    STL10 image:             (96, 96, 3)\n",
    "    Tensor:                  (3, 96, 96)\n",
    "    Data stack (all images): (5000, 3, 96, 96)\n",
    "    Matrix X (flattened):    (5000, 27648)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all 5000 images as a single batch into memory\n",
    "    # DataLoader is used to load data in batches, but we want to load all data at once\n",
    "    # iter(data_loader) converts it to an iterator\n",
    "    # next(...) gets the first (and only) batch from the iterator\n",
    "    data_loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    images, labels = next(iter(data_loader))\n",
    "\n",
    "    # Reshapes (flattens) each image in the batch into a 1D vector \n",
    "    # images.view(num_images, -1) -> \"Make the first dimension num_images and calculate whatever is left for the second dimension.\"\n",
    "    # (num_images, channels, height, width) -> (num_images, num_pixels)\n",
    "    num_images, channels, height, width = images.shape\n",
    "    flattened_images = images.view(num_images, -1)\n",
    "\n",
    "    return data.TensorDataset(flattened_images, labels)\n",
    "\n",
    "class SimCLR(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    @todo I adapted these from the SimCLR class from the 001_test_sim_clr.ipynb tutorial notebook\n",
    "    There it is used for training and feature extraction\n",
    "    We can remove the training logic - all we need is the pretrained base encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        \"\"\"\n",
    "        PyTorch Lightning's load_from_checkpoint (called in cells below) handles hyperparameter loading automatically,\n",
    "        just grabs them from the checkpoint itself so we don't have to pass them when we initialise SimCLR class, or call \n",
    "        load_from_checkpoint\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters() # \n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        \n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        \n",
    "        # We don't actually need this as we're just extracting features (from the base encoder)\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "@torch.no_grad()\n",
    "def prepare_features_simclr_representations(model, dataset):\n",
    "    \"\"\"\n",
    "    This removes the projection head of the SimCLR model and uses the base encoder to extract feature representations \n",
    "    for each image in the (in this case STL10) dataset.\n",
    "\n",
    "    The projection head is the \"small neural network projection head g(·) that maps representations to the space where contrastive loss is applied\".\n",
    "    The authors of the SimCLR paper note that they \"throw away the projection head g(·) and use encoder f(·) and representation h for downstream tasks.\"\n",
    "    \n",
    "    \"A nonlinear projection head improves the representation quality of the layer before it\" but \n",
    "    \"the hidden layer before the projection head is a better representation than the layer after\".\n",
    "    \"\"\"\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.) - Identity just returns its input, performs no operation\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        feats.append(batch_feats.detach().cpu()) # @todo: what are detatch() and cpu() doing here?\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    # @todo what is a Tensor?\n",
    "    return data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained SimCLR model\n",
    "# \"evaluation mode\" gives consistent and stable feature representations \n",
    "# - cos it disables \"dropout\" (where during training neurons are randomly set to zero to prevent overfitting) \n",
    "# and \"fixes batch normalization statistics\".\n",
    "# So eval mode makes the outputs suitable for analysis with PCA (but I don't know what any of this stuff is, so need to read)\n",
    "model = SimCLR.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run PCA on the raw STL10 images, and on the corresponding SimCLR representations of those images\n",
    "num_components = 500\n",
    "\n",
    "stl10_dataset = STL10(root=DATASET_PATH, split='train', download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Prepare the raw STL10 images for PCA\n",
    "stl10_prepared = prepare_features_stl10_images(stl10_dataset)\n",
    "stl10_feats, stl10_labels = stl10_prepared.tensors\n",
    "\n",
    "# Run PCA on the raw STL10 images\n",
    "pca_stl10 = PCA(num_components)\n",
    "pca_stl10.fit(stl10_feats.numpy())\n",
    "explained_variance_stl10 = pca_stl10.explained_variance_ratio_\n",
    "cumulative_variance_stl10 = np.cumsum(explained_variance_stl10)\n",
    "\n",
    "# Print the # principal components required to explain 95% of the variance\n",
    "# will print 1 num components above are not sufficient to explain 95% variance\n",
    "print(\"Number of STL10 components to explain 95% variance:\", np.argmax(cumulative_variance_stl10 >= 0.95) + 1) # 940\n",
    "print(\"Variance explained by 225 components:\", cumulative_variance_stl10[224])\n",
    "\n",
    "# Extract SimCLR representations for the same images; prepare representations for PCA\n",
    "simclr_prepared = prepare_features_simclr_representations(model, stl10_dataset)\n",
    "simclr_feats, simclr_labels = simclr_prepared.tensors\n",
    "\n",
    "print(\"First 10 labels in STL10 features:\", stl10_labels[:10])\n",
    "print(\"First 10 labels in SimCLR features:\", stl10_labels[:10])\n",
    "\n",
    "# Run PCA on the SimCLR representations\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_feats.numpy())\n",
    "explained_variance_simclr = pca_simclr.explained_variance_ratio_\n",
    "cumulative_variance_simclr = np.cumsum(explained_variance_simclr)\n",
    "\n",
    "# Plot results\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_variance_stl10, label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, cumulative_variance_simclr, label=\"SimCLR Representations\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's try PCA on earlier layers of the base encoder from the SimCLR mode\n",
    "\n",
    "class SimCLRWithIntermediateLayerOutputs(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        \n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        \n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "# Function to register hooks and capture outputs from intermediate layers\n",
    "def register_hooks(model, layers):\n",
    "    features = {}\n",
    "\n",
    "    def hook(module, input, output, layer_name):\n",
    "        features[layer_name] = output.detach()\n",
    "\n",
    "    for layer_name in layers:\n",
    "        layer = dict([*model.named_modules()])[layer_name]\n",
    "        layer.register_forward_hook(lambda module, input, output, layer_name=layer_name: hook(module, input, output, layer_name))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Modified function to prepare features with intermediate layer outputs\n",
    "@torch.no_grad()\n",
    "def prepare_features_simclr_representations_multi_layer(model, dataset, layers_to_capture):\n",
    "    # Prepare model and register hooks\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Register hooks to capture specific intermediate layers\n",
    "    features = register_hooks(network, layers_to_capture)\n",
    "    \n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels, intermediate_features = [], [], {layer: [] for layer in layers_to_capture}\n",
    "    \n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "        \n",
    "        # Collect intermediate layer outputs\n",
    "        for layer in layers_to_capture:\n",
    "            # Final linear layer outputs a 2d tensor; but intermediate layers don't, so we flatten them ready for PCA \n",
    "            layer_output_flattened = features[layer].view(features[layer].size(0), -1) \n",
    "            intermediate_features[layer].append(layer_output_flattened.cpu())\n",
    "    \n",
    "    # Concatenate results for each layer\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    intermediate_features = {layer: torch.cat(intermediate_features[layer], dim=0) for layer in layers_to_capture}\n",
    "    \n",
    "    return data.TensorDataset(feats, labels), intermediate_features\n",
    "\n",
    "# Load the pretrained SimCLR model\n",
    "model = SimCLRWithIntermediateLayerOutputs.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model.eval()\n",
    "\n",
    "layers_to_capture = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "# Extract SimCLR representations and intermediate features\n",
    "simclr_prepared, intermediate_features = prepare_features_simclr_representations_multi_layer(model, stl10_dataset, layers_to_capture)\n",
    "simclr_feats, simclr_labels = simclr_prepared.tensors\n",
    "layer1_feats = intermediate_features['layer1']\n",
    "layer2_feats = intermediate_features['layer2']\n",
    "layer4_feats = intermediate_features['layer4']\n",
    "\n",
    "# Layer 1 features shape:     torch.Size([5000, 36864])\n",
    "# Layer 2 features shape:     torch.Size([5000, 18432])\n",
    "# Layer 4 features shape:     torch.Size([5000, 4608])])\n",
    "# Final Layer features shape: torch.Size([5000, 512])\n",
    "print(\"STL10 features shape:\", stl10_feats.shape)\n",
    "print(\"Layer 1 features shape:\", layer1_feats.shape) \n",
    "print(\"Layer 2 features shape:\", layer2_feats.shape) \n",
    "print(\"Layer 4 features shape:\", layer4_feats.shape)\n",
    "print(\"Final Layer features shape:\", simclr_feats.shape)\n",
    "\n",
    "num_components = 500\n",
    "\n",
    "# Run PCA on the SimCLR layer 1\n",
    "pca_simclr_layer1 = PCA(n_components=num_components)\n",
    "pca_simclr_layer1.fit(layer1_feats.numpy())\n",
    "explained_variance_simclr_layer1 = pca_simclr_layer1.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer1 = np.cumsum(explained_variance_simclr_layer1)\n",
    "\n",
    "# Run PCA on the SimCLR layer 2\n",
    "pca_simclr_layer2 = PCA(n_components=num_components)\n",
    "pca_simclr_layer2.fit(layer2_feats.numpy())\n",
    "explained_variance_simclr_layer2 = pca_simclr_layer2.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer2 = np.cumsum(explained_variance_simclr_layer2)\n",
    "\n",
    "# Run PCA on the SimCLR layer 4\n",
    "pca_simclr_layer4 = PCA(n_components=num_components)\n",
    "pca_simclr_layer4.fit(layer4_feats.numpy())\n",
    "explained_variance_simclr_layer4 = pca_simclr_layer4.explained_variance_ratio_\n",
    "cumulative_variance_simclr_layer4 = np.cumsum(explained_variance_simclr_layer4)\n",
    "\n",
    "# Run PCA on final linear layer\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_feats.numpy())\n",
    "explained_variance_simclr = pca_simclr.explained_variance_ratio_\n",
    "cumulative_variance_simclr = np.cumsum(explained_variance_simclr)\n",
    "\n",
    "# Print the # principal components required to explain 95% of the variance\n",
    "print(\"Number of SimCLR components to explain 95% variance:\", np.argmax(cumulative_variance_simclr >= 0.95) + 1) # 225\n",
    "\n",
    "# Plot cumulative explained variance against number of principal components\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_variance_stl10, label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer1, label=\"SimCLR Layer 1\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer2, label=\"SimCLR Layer 2\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr_layer4, label=\"SimCLR Layer 4\", marker='x')\n",
    "plt.plot(plot_components, cumulative_variance_simclr, label=\"SimCLR Final Layer\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot explained variance (log) against number of principal components (log)\n",
    "plot_components = np.log10(range(1, num_components + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, np.log10(explained_variance_stl10), label=\"Raw STL10 Images\", marker='o')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr_layer1), label=\"SimCLR Layer 1\", marker='x')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr_layer2), label=\"SimCLR Layer 2\", marker='x')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr_layer4), label=\"SimCLR Layer 4\", marker='x')\n",
    "plt.plot(plot_components, np.log10(explained_variance_simclr), label=\"SimCLR Final Layer\", marker='x')\n",
    "\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"PCA: Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "### The initial PCs for the raw images capture a lot of simple pixel-level variance - raw images explain more variance vs. SimCLR final layer\n",
    "### After a certain number of PCs (~40), SimCLR explains a higher level of the variance vs. the raw images\n",
    "### For SimCLR, each principal component captures more complex, high-level features (more meaningful variance rather than noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SimCLR: Cross-validate the findings from the PCA analysis by plotting #PCs for e.g. 4000 images, and plot explained variance for the other 1000\n",
    "\n",
    "# Run PCA on \"training\" subset of the representations\n",
    "simclr_train, simclr_test = torch.utils.data.random_split(simclr_feats, [4000, 1000])\n",
    "pca_simclr = PCA(n_components=num_components)\n",
    "pca_simclr.fit(simclr_train)\n",
    "explained_var_simclr_train = pca_simclr.explained_variance_ratio_\n",
    "\n",
    "# Fit the PCA model on the test set \n",
    "simclr_test_transformed = pca_simclr.transform(simclr_test)\n",
    "explained_var_simclr_test = np.var(simclr_test_transformed, axis=0) / np.sum(np.var(simclr_test, axis=0))\n",
    "\n",
    "# Compute cumulative explained variances\n",
    "cumulative_variance_train = np.cumsum(explained_var_simclr_train)\n",
    "cumulative_variance_test = np.cumsum(explained_var_simclr_test)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_train) + 1), cumulative_variance_train, label=\"Training Set\", marker='o')\n",
    "plt.plot(range(1, len(cumulative_variance_test) + 1), cumulative_variance_test, label=\"Test Set\", marker='x')\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"SimCLR final layer: Cross-Validation of PCA Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Raw images: cross-validate the findings from the PCA analysis by plotting #PCs for e.g. 4000 images, and plot explained variance for the other 1000\n",
    "\n",
    "# Run PCA on \"training\" subset of the representations\n",
    "stl10_train, stl10_test = torch.utils.data.random_split(stl10_feats, [4000, 1000])\n",
    "pca_stl10 = PCA(n_components=num_components)\n",
    "pca_stl10.fit(stl10_train)\n",
    "explained_var_stl10_train = pca_stl10.explained_variance_ratio_\n",
    "\n",
    "# Fit the PCA model on the test set \n",
    "stl10_test_transformed = pca_stl10.transform(stl10_test)\n",
    "explained_var_stl10_test = np.var(stl10_test_transformed, axis=0) / np.sum(np.var(stl10_test, axis=0))\n",
    "\n",
    "# Compute cumulative explained variances\n",
    "cumulative_variance_train = np.cumsum(explained_var_stl10_train)\n",
    "cumulative_variance_test = np.cumsum(explained_var_stl10_test)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_train) + 1), cumulative_variance_train, label=\"Training Set\", marker='o')\n",
    "plt.plot(range(1, len(cumulative_variance_test) + 1), cumulative_variance_test, label=\"Test Set\", marker='x')\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Raw STL10: Cross-Validation of PCA Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
