{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code for downloading the pretrained model, and the SimCLR class, is based on this tutorial here: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial17/SimCLR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Your image dataset should live here\n",
    "IMAGE_DATASET_PATH = \"../../data\"\n",
    "\n",
    "# Your pretrained models should live here\n",
    "MODELS_DIR = \"../../models\"\n",
    "PRETRAINED_SIMCLR_FILENAME = \"SimCLR.ckpt\"\n",
    "PRETRAINED_SIMCLR_PATH = os.path.join(MODELS_DIR, PRETRAINED_SIMCLR_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load (or download) the pretrained model\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial17/\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Check whether the pretrained model file already exists locally. If not, try downloading it\n",
    "if not os.path.isfile(PRETRAINED_SIMCLR_PATH):\n",
    "    file_url = base_url + PRETRAINED_SIMCLR_FILENAME\n",
    "    print(f\"Downloading {file_url}...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(file_url, PRETRAINED_SIMCLR_PATH)\n",
    "    except HTTPError as e:\n",
    "        print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
    "\n",
    "print(f\"Already downloaded pretrained model: {file_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define SimCLR class and logic for extracting feature representations\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_workers = os.cpu_count()\n",
    "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        \n",
    "        # Base ResNet18 backbone (pretrained=False, because we load custom weights later, from the SimCLR checkpoint file)\n",
    "        self.convnet = torchvision.models.resnet18(pretrained=False)\n",
    "        \n",
    "        # This is the projection head, only needed during training. For downstream tasks it is disposed of\n",
    "        # and the final linear layer output is used (Chen et al., 2020) \n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.intermediate_layers_to_capture =[]\n",
    "        self.intermediate_layer_features = {}\n",
    "\n",
    "    def load_pretrained(self, checkpoint_path=PRETRAINED_SIMCLR_PATH):\n",
    "        \"\"\"\n",
    "        Load pretrained SimCLR weights\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.load_state_dict(checkpoint['state_dict'])\n",
    "        self.to(self.device)\n",
    "        self.eval()\n",
    "\n",
    "    def set_intermediate_layers_to_capture(self, layers):\n",
    "        \"\"\"\n",
    "        Register hooks to capture features from intermediate layers\n",
    "        \"\"\"\n",
    "        self.intermediate_layers_to_capture = layers\n",
    "        intermediate_layer_features = {}\n",
    "\n",
    "        def get_hook(layer_name):\n",
    "            def hook(module, input, output):\n",
    "                intermediate_layer_features[layer_name] = output.detach()\n",
    "            return hook\n",
    "\n",
    "        for layer_name in layers:\n",
    "            layer = dict([*self.convnet.named_modules()])[layer_name]\n",
    "            layer.register_forward_hook(get_hook(layer_name))\n",
    "\n",
    "        self.intermediate_layer_features = intermediate_layer_features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, dataset: Dataset) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Run the pretrained SimCLR model on the image data, and capture features from final layer and intermediate layers.\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): A PyTorch dataset containing input images and labels.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: A dictionary containing:\n",
    "                - Intermediate layer features as tensors.\n",
    "                - Final layer features under 'final_layer'.\n",
    "                - Labels under 'labels'.\n",
    "        \"\"\"\n",
    "        self.convnet.fc = nn.Identity()  # Removing projection head g(.)\n",
    "        self.eval()\n",
    "        self.to(self.device)\n",
    "        \n",
    "        # Encode all images\n",
    "        data_loader = DataLoader(dataset, batch_size=64, num_workers=self.num_workers, shuffle=False, drop_last=False)\n",
    "        feats, labels, intermediate_features = [], [], {layer: [] for layer in self.intermediate_layers_to_capture}\n",
    "\n",
    "        for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "            batch_imgs = batch_imgs.to(self.device)\n",
    "            batch_feats = self.convnet(batch_imgs)\n",
    "            \n",
    "            feats.append(batch_feats.detach().cpu())\n",
    "            labels.append(batch_labels)\n",
    "            \n",
    "            # Collect intermediate layer outputs\n",
    "            for layer in self.intermediate_layers_to_capture:\n",
    "                # Final linear layer outputs a 2d tensor; but intermediate layers don't, so we flatten them (ready for PCA etc.)\n",
    "                layer_output_flattened = self.intermediate_layer_features[layer].view(self.intermediate_layer_features[layer].size(0), -1) \n",
    "                intermediate_features[layer].append(layer_output_flattened.cpu())\n",
    "        \n",
    "        # Concatenate results for each layer\n",
    "        feats = torch.cat(feats, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        intermediate_features = {layer: torch.cat(intermediate_features[layer], dim=0) for layer in self.intermediate_layers_to_capture}\n",
    "\n",
    "        return {**intermediate_features, 'final_layer': feats, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare your image data\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Generate a random set of images (TODO: replace with your images)\n",
    "num_images = 600\n",
    "image_height, image_width = 224, 224\n",
    "random_grayscale_images = torch.rand((num_images, 1, image_height, image_width), dtype=torch.float32)\n",
    "random_rgb_images = random_grayscale_images.repeat(1, 3, 1, 1)  # Shape: (N, 3, H, W)\n",
    "random_labels = torch.arange(0, num_images)\n",
    "image_dataset = TensorDataset(random_rgb_images, random_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run your image data through the pretrained SimCLR model, and extract feature representations\n",
    "\n",
    "intermediate_layers = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "sim_clr = SimCLR()\n",
    "sim_clr.load_pretrained()\n",
    "sim_clr.set_intermediate_layers_to_capture(intermediate_layers)\n",
    "feats = sim_clr.extract_features(image_dataset)\n",
    "\n",
    "layer1_feats = feats['layer1']\n",
    "layer2_feats = feats['layer2']\n",
    "layer3_feats = feats['layer3']\n",
    "layer4_feats = feats['layer4']\n",
    "final_layer_feats = feats['final_layer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
