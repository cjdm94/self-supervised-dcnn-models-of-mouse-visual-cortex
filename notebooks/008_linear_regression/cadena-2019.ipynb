{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from Cadena et al. 2019\n",
    "# NOTE: they applied to their images, shown to the monkeys, a circular aperture mask with cosine fade-out\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('../../data/cadena_plosCB19/cadena_ploscb_data.pkl', 'rb') as g:\n",
    "    loaded_data = pickle.load(g)\n",
    "\n",
    "# Cadena found that the transfer‐learning approach (using VGG features) reached near-optimal performance with as little as 20% of the available data\n",
    "SAMPLE_SIZE = 1400\n",
    "rng = np.random.RandomState(42)\n",
    "SAMPLE_INDICES = np.random.choice(loaded_data[\"images\"].shape[0], SAMPLE_SIZE, replace=False)\n",
    "\n",
    "# Check the available keys and shapes\n",
    "for key, value in loaded_data.items():\n",
    "    print(f\"{key}: {value.shape if isinstance(value, np.ndarray) else type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess neural data\n",
    "\n",
    "responses = loaded_data[\"responses\"]\n",
    "print(\"Responses shape:\", responses.shape) # (4, 7250, 166) -> 4 repetitions, 7250 images, 166 neurons\n",
    "\n",
    "# Check how many images have no valid responses across all neurons and repetitions\n",
    "fully_missing_images = np.isnan(loaded_data[\"responses\"]).all(axis=(0, 2)) # Check over repetitions & neurons\n",
    "num_fully_missing = fully_missing_images.sum()\n",
    "print(f\"Fully missing images: {num_fully_missing}/{loaded_data['responses'].shape[1]}\")\n",
    "\n",
    "# Load neural responses and average over the 4 repetitions\n",
    "averaged_responses = np.nanmean(responses, axis=0) # Shape: (7250, 166)\n",
    "print(\"Averaged Responses shape:\", averaged_responses.shape)\n",
    "\n",
    "averaged_responses_cleaned = np.nan_to_num(averaged_responses) # Apply Cadena's preprocessing: Replace NaNs with 0\n",
    "print('Responses sample:', averaged_responses_cleaned[:20])\n",
    "\n",
    "# Select only the first 3625 samples, because we will only use half the images\n",
    "processed_neural_responses = averaged_responses_cleaned[SAMPLE_INDICES]\n",
    "print('Final responses shape:', processed_neural_responses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare images for VGG-19\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define VGG-compatible transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.Grayscale(num_output_channels=3), # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply transformation to all images (using half for now due to memory constraints)\n",
    "sample = loaded_data[\"images\"][SAMPLE_INDICES]\n",
    "images = np.stack([\n",
    "    transform(Image.fromarray(img.astype(np.uint8))).numpy() for img in sample\n",
    "])\n",
    "\n",
    "print(\"Transformed Images Shape:\", images.shape)  # (7250, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features in batches and save to disk\n",
    "\n",
    "# import torch\n",
    "# import torchvision.models as models\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# feature_save_path = \"vgg_features_batches.npy\"\n",
    "\n",
    "# if os.path.exists(feature_save_path):\n",
    "#     file_size = os.path.getsize(feature_save_path) / (1024 * 1024)\n",
    "#     print(f\"Features already saved. File Size: {file_size:.2f} MB\")\n",
    "# else:\n",
    "#     class VGGFeatureExtractor(torch.nn.Module):\n",
    "#         def __init__(self, layer_idx=8):  # conv3_1 is at index 8 in VGG-19\n",
    "#             super(VGGFeatureExtractor, self).__init__()\n",
    "#             self.features = torch.nn.Sequential(*list(models.vgg19(pretrained=True).features.children())[:layer_idx+1])\n",
    "\n",
    "#         def forward(self, x):\n",
    "#             return self.features(x)\n",
    "\n",
    "#     # Device configuration (GPU if available, otherwise CPU)\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     feature_extractor = VGGFeatureExtractor().to(device).eval()\n",
    "\n",
    "#     # Convert images to Torch tensor dataset\n",
    "#     images_tensor = torch.tensor(images, dtype=torch.float32).to(device)  # (7250, 3, 224, 224)\n",
    "\n",
    "#     # DataLoader with smaller batch size\n",
    "#     batch_size = 8  # Reduce if still running out of memory\n",
    "#     dataset = TensorDataset(images_tensor)\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     # Process images in batches and save incrementally\n",
    "#     with torch.no_grad():  # Disable autograd for memory efficiency\n",
    "#         for batch_idx, (batch,) in enumerate(dataloader):\n",
    "#             batch = batch.to(device)  # Move batch to GPU (if available)\n",
    "#             features = feature_extractor(batch).cpu().numpy()  # Move to CPU immediately\n",
    "            \n",
    "#             # Append to .npy file (save in small increments)\n",
    "#             with open(feature_save_path, \"ab\") as f:  # \"ab\" = append binary mode\n",
    "#                 np.save(f, features)\n",
    "            \n",
    "#             # Free memory\n",
    "#             del batch, features\n",
    "#             torch.cuda.empty_cache()  # Clears GPU cache\n",
    "\n",
    "#             print(f\"Processed batch {batch_idx + 1}/{len(dataloader)} and saved to disk\")\n",
    "\n",
    "#     print(f\"Feature extraction complete! Saved to {feature_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory-efficient writing features to disk\n",
    "\n",
    "# import torch\n",
    "# import torchvision.models as models\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Define feature extractor (VGG-19 up to conv3_1)\n",
    "# class VGGFeatureExtractor(torch.nn.Module):\n",
    "#     def __init__(self, layer_idx=8):  # Extract conv3_1 features\n",
    "#         super(VGGFeatureExtractor, self).__init__()\n",
    "#         self.features = torch.nn.Sequential(*list(models.vgg19(pretrained=True).features.children())[:layer_idx+1])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.features(x)\n",
    "\n",
    "# # Device configuration (Use GPU if available)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# feature_extractor = VGGFeatureExtractor().to(device).eval()\n",
    "\n",
    "# # Convert images to Torch tensor dataset\n",
    "# images_tensor = torch.tensor(images, dtype=torch.float32).to(device)  # (7250, 3, 224, 224)\n",
    "\n",
    "# # DataLoader for batch processing\n",
    "# batch_size = 8  # Adjust based on available memory\n",
    "# dataset = TensorDataset(images_tensor)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # File to save extracted features\n",
    "# feature_save_path = \"vgg_features_batches.npz\"\n",
    "\n",
    "# # Remove old file if it exists\n",
    "# if os.path.exists(feature_save_path):\n",
    "#     os.remove(feature_save_path)\n",
    "\n",
    "# # List to store batch paths\n",
    "# batch_files = []\n",
    "\n",
    "# # Extract and save features batch-wise\n",
    "# with torch.no_grad():  # Disable autograd for efficiency\n",
    "#     for batch_idx, (batch,) in enumerate(dataloader):\n",
    "#         batch = batch.to(device)  # Move batch to GPU (if available)\n",
    "#         features = feature_extractor(batch).cpu().numpy()  # Move to CPU\n",
    "\n",
    "#         # Save each batch as a separate .npy file\n",
    "#         batch_filename = f\"vgg_features_batch_{batch_idx}.npy\"\n",
    "#         np.save(batch_filename, features)\n",
    "#         batch_files.append(batch_filename)  # Keep track of saved files\n",
    "\n",
    "#         # Free memory\n",
    "#         del batch, features\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         print(f\"Processed batch {batch_idx + 1}/{len(dataloader)} - Written to {batch_filename}\")\n",
    "\n",
    "# # **Merge All Batches into One Final .npz File**\n",
    "# print(\"Merging batches into final compressed file...\")\n",
    "# all_features = [np.load(f) for f in batch_files]  # Load each batch one at a time\n",
    "# final_features = np.concatenate(all_features, axis=0)  # Merge efficiently\n",
    "# np.savez_compressed(feature_save_path, features=final_features)  # Save final file\n",
    "\n",
    "# # Delete temporary batch files to save space\n",
    "# for file in batch_files:\n",
    "#     os.remove(file)\n",
    "\n",
    "# print(f\"Feature extraction complete! Final dataset saved to {feature_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "PATH_TO_FEATURES = \"../../data/cadena_plosCB19/vgg_features.npy\"\n",
    "\n",
    "if os.path.exists(PATH_TO_FEATURES):\n",
    "    print(f\"Features file '{PATH_TO_FEATURES}' exists. Loading features...\")\n",
    "else:\n",
    "    print(f\"Features file does not exist. Extracting features...\")\n",
    "    \n",
    "    # Define feature extractor (VGG-19 up to conv3_1)\n",
    "    class VGGFeatureExtractor(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(VGGFeatureExtractor, self).__init__()\n",
    "            # Extract feature maps (256, 56, 56) from conv3_1 layer (BEFORE max pooling)\n",
    "            self.features = torch.nn.Sequential(*list(models.vgg19(pretrained=True).features.children())[:14])\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.features(x)\n",
    "\n",
    "    # Device configuration (Use GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    feature_extractor = VGGFeatureExtractor().to(device).eval()\n",
    "\n",
    "    # Convert images to Torch tensor dataset\n",
    "    images_tensor = torch.tensor(images, dtype=torch.float32).to(device)  # Shape: (3625, 3, 224, 224)\n",
    "\n",
    "    # DataLoader for batch processing\n",
    "    batch_size = 8\n",
    "    dataset = TensorDataset(images_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Store all batches in memory\n",
    "    all_batches = []\n",
    "\n",
    "    # Extract features batch-wise and store in RAM\n",
    "    with torch.no_grad():  # Disable autograd for efficiency\n",
    "        for batch_idx, (batch,) in enumerate(dataloader):\n",
    "            batch = batch.to(device)  # Move batch to GPU (if available)\n",
    "            features = feature_extractor(batch).cpu().numpy()  # Move to CPU\n",
    "\n",
    "            all_batches.append(features)  # Store batch in memory\n",
    "\n",
    "            # Free memory\n",
    "            del batch, features\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print(f\"Processed batch {batch_idx + 1}/{len(dataloader)}\")\n",
    "\n",
    "    # Concatenate all batches into a single NumPy array\n",
    "    vgg_features = np.concatenate(all_batches, axis=0)\n",
    "    print(\"Final Features Shape:\", vgg_features.shape) # Expected: (3625, 256, 56, 56)\n",
    "    np.save(PATH_TO_FEATURES, vgg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "vgg_features = np.load(PATH_TO_FEATURES, mmap_mode=\"r\") # Use mmap_mode for large files\n",
    "X = vgg_features.reshape(vgg_features.shape[0], -1) # Flatten from (3625, 256, 56, 56) (3625, feature_dimensions)\n",
    "y = processed_neural_responses\n",
    "print(\"Final Shapes -> X:\", X.shape, \"y:\", processed_neural_responses.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "ridge_reg = Ridge(alpha=10000000)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "y_pred = ridge_reg.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test R² Score: {r2:.3f}\")\n",
    "\n",
    "def compute_fev(y_true, y_pred):\n",
    "    noise_variance = np.var(y_true - np.mean(y_true, axis=0), axis=0)\n",
    "    total_variance = np.var(y_true, axis=0)\n",
    "    explained_variance = np.var(y_pred, axis=0)\n",
    "    fev = 1 - (total_variance - explained_variance) / (total_variance - noise_variance)\n",
    "    return np.mean(fev)\n",
    "\n",
    "fev_score = compute_fev(y_test, y_pred)\n",
    "print(f\"Fraction of Explainable Variance (FEV): {fev_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Poisson regression model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "vgg_features = np.load(PATH_TO_FEATURES, mmap_mode=\"r\") # Use mmap_mode for large files\n",
    "\n",
    "# X: (3625, num_features) and y: (3625, 166)\n",
    "X = vgg_features.reshape(vgg_features.shape[0], -1) # Flatten from (3625, 256, 56, 56) (3625, feature_dimensions)\n",
    "y = processed_neural_responses\n",
    "print(\"Final Shapes -> X:\", X.shape, \"y:\", processed_neural_responses.shape)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_neurons = y_train.shape[1]\n",
    "models = []\n",
    "y_pred_test_all = np.zeros_like(y_test)\n",
    "r2_list = []\n",
    "\n",
    "# Loop over each neuron (output dimension)\n",
    "for i in range(n_neurons):\n",
    "    # Fit a separate PoissonRegressor for neuron i\n",
    "    model = PoissonRegressor(alpha=0.01, max_iter=1000)\n",
    "    model.fit(X_train, y_train[:, i])\n",
    "    models.append(model)\n",
    "    \n",
    "    # Predict on the test set for this neuron\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_test_all[:, i] = y_pred\n",
    "    \n",
    "    # Compute R² for this neuron and store it\n",
    "    r2 = r2_score(y_test[:, i], y_pred)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "# Compute mean R² across neurons\n",
    "mean_r2 = np.mean(r2_list)\n",
    "print(f\"Mean Test R² Score: {mean_r2:.3f}\")\n",
    "\n",
    "# Optionally, define the FEV function and compute average FEV\n",
    "def compute_fev(y_true, y_pred):\n",
    "    # Compute noise variance, total variance, and explained variance for each neuron\n",
    "    noise_variance = np.var(y_true - np.mean(y_true, axis=0), axis=0)\n",
    "    total_variance = np.var(y_true, axis=0)\n",
    "    explained_variance = np.var(y_pred, axis=0)\n",
    "    fev = 1 - (total_variance - explained_variance) / (total_variance - noise_variance)\n",
    "    return np.mean(fev)\n",
    "\n",
    "fev_score = compute_fev(y_test, y_pred_test_all)\n",
    "print(f\"Mean Fraction of Explainable Variance (FEV): {fev_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
