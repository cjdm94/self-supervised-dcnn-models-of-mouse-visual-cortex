{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "# imresps.npy is of shape (1573, 2, 15363), where 1573 is number of images, 2 repeats each, and 15363 neurons recorded\n",
    "# stimids.npy has the image id (matching the image dataset ~selection1866~) for each stimulus number, \n",
    "# so of you want to see what image was presented on imresps[502] you would check stim_ids[502]\n",
    "\n",
    "PATH_TO_DATA = '../../data/neural'\n",
    "\n",
    "imresps = np.load(path.join(PATH_TO_DATA, 'imresps.npy'))\n",
    "stimids = np.load(path.join(PATH_TO_DATA, 'stimids.npy'))\n",
    "\n",
    "print(imresps.shape) # (1573, 2, 15363)\n",
    "print(stimids.shape) # (1573,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signal_related_variance(resp_a, resp_b, mean_center=True):\n",
    "    \"\"\"\n",
    "    compute the fraction of signal-related variance for each neuron,\n",
    "    as per Stringer et al Nature 2019. Cross-validated by splitting\n",
    "    responses into two halves. Note, this only is \"correct\" if resp_a\n",
    "    and resp_b are *not* averages of many trials.\n",
    "\n",
    "    Args:\n",
    "        resp_a (ndarray): n_stimuli, n_cells\n",
    "        resp_b (ndarray): n_stimuli, n_cells\n",
    "\n",
    "    Returns:\n",
    "        fraction_of_stimulus_variance: 0-1, 0 is non-stimulus-caring, 1 is only-stimulus-caring neurons\n",
    "        stim_to_noise_ratio: ratio of the stim-related variance to all other variance\n",
    "    \"\"\"\n",
    "    if len(resp_a.shape) > 2:\n",
    "        # if the stimulus is multi-dimensional, flatten across all stimuli\n",
    "        resp_a = resp_a.reshape(-1, resp_a.shape[-1])\n",
    "        resp_b = resp_b.reshape(-1, resp_b.shape[-1])\n",
    "    ns, nc = resp_a.shape\n",
    "    if mean_center:\n",
    "        # mean-center the activity of each cell\n",
    "        resp_a = resp_a - resp_a.mean(axis=0)\n",
    "        resp_b = resp_b - resp_b.mean(axis=0)\n",
    "    \n",
    "    # compute the cross-trial stimulus covariance of each cell\n",
    "    # dot-product each cell's (n_stim, ) vector from one half\n",
    "    # with its own (n_stim, ) vector on the other half\n",
    "\n",
    "    covariance = (resp_a * resp_b).sum(axis=0) / ns\n",
    "\n",
    "    # compute the variance of each cell across both halves\n",
    "    resp_a_variance = (resp_a**2).sum(axis=0) / ns\n",
    "    resp_b_variance = (resp_b**2).sum(axis=0) / ns\n",
    "    total_variance = (resp_a_variance + resp_b_variance) / 2\n",
    "\n",
    "    if np.any(total_variance < 1e-12):\n",
    "        print(f\"Warning: Near-zero total variance for neurons: {np.where(total_variance < 1e-12)[0]}\")\n",
    "\n",
    "    # compute the fraction of the total variance that is\n",
    "    # captured in the covariance\n",
    "    fraction_of_stimulus_variance = covariance / total_variance\n",
    "\n",
    "    # if you want, you can compute SNR as well:\n",
    "    stim_to_noise_ratio = fraction_of_stimulus_variance / (\n",
    "        1 - fraction_of_stimulus_variance\n",
    "    )\n",
    "\n",
    "    return fraction_of_stimulus_variance, stim_to_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the null distribution of SRV values for all neurons\n",
    "\n",
    "# imresps shape = (1573, 2, 15363)\n",
    "# responses in imresps shape = (2, 15363)\n",
    "num_stimuli = imresps.shape[0] # 1573\n",
    "num_repeats = imresps.shape[1] # 2\n",
    "num_neurons = imresps.shape[2] # 15363\n",
    "n_shuffles = 100\n",
    "\n",
    "null_srv_all_neurons = [] # shape (n_shuffles, num_neurons)\n",
    "\n",
    "for _ in range(n_shuffles):\n",
    "    # Shuffle stimulus indices *twice* to create two independent splits!\n",
    "    shuffled_indices_A = np.random.permutation(num_stimuli)\n",
    "    shuffled_indices_B = np.random.permutation(num_stimuli)\n",
    "\n",
    "    # Now for the splits, we can just use fixed repeat indices, \n",
    "    # because for each split, at index N the responses correspond to different stimuli\n",
    "    # e.g. split_A = [ stim_100_repeat_1, stim_2_repeat_1, stim_19_repeat_1, ... ]\n",
    "    # e.g. split_B = [ stim_543_repeat_2, stim_345_repeat_2, stim_3_repeat_2, ... ]\n",
    "    split_A = imresps[shuffled_indices_A, 0, :]\n",
    "    split_B = imresps[shuffled_indices_B, 1, :]\n",
    "\n",
    "    # Compute SRV for the shuffled data\n",
    "    fraction_of_stimulus_variance, _ = compute_signal_related_variance(split_A, split_B)\n",
    "    null_srv_all_neurons.append(fraction_of_stimulus_variance)\n",
    "\n",
    "null_srv_all_neurons = np.array(null_srv_all_neurons)\n",
    "null_srv_all_neurons.shape # (100, 15363)\n",
    "\n",
    "print(null_srv_all_neurons[0])\n",
    "print(null_srv_all_neurons[33])\n",
    "\n",
    "# e.g. if neuron_index = 0, it will plot the SRV value for neuron 0 across all shuffles\n",
    "neuron_index = 0\n",
    "plt.hist([srv[neuron_index] for srv in null_srv_all_neurons], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the real SRV for each neuron\n",
    "\n",
    "# split_A_real = imresps[:, 0, :] # First repeat for each stimulus\n",
    "# split_B_real = imresps[:, 1, :] # Second repeat for each stimulus\n",
    "\n",
    "split_A, split_B = [], []\n",
    "for responses in imresps: # responses shape: (2, n_neurons)\n",
    "    indices = np.random.permutation(2) # Randomly shuffle [0, 1]\n",
    "    split_A.append(responses[indices[0]]) # Assign one repeat to split_A\n",
    "    split_B.append(responses[indices[1]]) # Assign the other to split_B\n",
    "\n",
    "split_A = np.array(split_A)  # Shape: (n_stimuli, n_neurons)\n",
    "split_B = np.array(split_B)  # Shape: (n_stimuli, n_neurons)\n",
    "\n",
    "# Compute SRV for real data\n",
    "real_srv_all_neurons, stim_to_noise_ratio = compute_signal_related_variance(split_A, split_B)\n",
    "\n",
    "print(real_srv_all_neurons)\n",
    "print(stim_to_noise_ratio)\n",
    "\n",
    "print(\"Real SRV shape:\", real_srv_all_neurons.shape) # Should be (15363,)\n",
    "\n",
    "plt.hist(real_srv_all_neurons, bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter neurons whose real SRV is in the top 90th percentile of its null distribution\n",
    "\n",
    "# This gives the 90th-percentile SRV value of the null distribution for each neuron\n",
    "# In other words the threshold for each neuron to be considered reliable\n",
    "# e.g. if neuron 0 has a null distribution of SRVs across 10 shuffles \n",
    "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], the threshold would be 0.9\n",
    "top_99th_percentile_null = np.percentile(null_srv_all_neurons, 99, axis=0)\n",
    "print(top_99th_percentile_null) # [0.03651716 0.03126347 0.03325775 ... 0.02738261 0.03546677 0.0333109 ]\n",
    "\n",
    "# Get indices of reliable neurons\n",
    "reliable_neuron_indices = np.where(real_srv_all_neurons >= top_99th_percentile_null)[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of reliable neurons: {len(reliable_neuron_indices)}\") # 5654\n",
    "print(f\"Indices of reliable neurons: {reliable_neuron_indices}\") # [   14    29    48 ... 15357 15358 15360]\n",
    "\n",
    "plt.hist(real_srv_all_neurons, bins=100, color='red', alpha=0.7)\n",
    "plt.hist(real_srv_all_neurons[reliable_neuron_indices], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(\"All Neurons: SRV all vs. SRV reliable\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(real_srv_all_neurons[reliable_neuron_indices], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Neurons\")\n",
    "plt.title(\"SRV Distribution for Reliable Neurons\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and preprocess images\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.transforms import Normalize, Compose, Resize, CenterCrop\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import utils as torch_utils\n",
    " \n",
    "PATH_TO_DATA = '../../data/selection1866'\n",
    "\n",
    "file_list = sorted(f for f in os.listdir(PATH_TO_DATA) if f.endswith('.mat'))\n",
    "stim_ids = stimids.astype(int)\n",
    "\n",
    "print(stim_ids)\n",
    "print(stimids)\n",
    "\n",
    "transform = Compose([\n",
    "    Resize(96), # Resize shortest edge to 96 (cut off the rightmost part of the image)\n",
    "    CenterCrop((96, 96)), # Crop to (96, 96)\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # !! Normalize expects input is already in the range [0, 1]\n",
    "])\n",
    "\n",
    "img_tensors, labels = [], []\n",
    "\n",
    "print('List:', file_list)\n",
    "\n",
    "# we have 1866 images here, but the neural response data only uses 1573 of them\n",
    "# because some ~300 images didn't have two repeats, so were disposed\n",
    "# therefore we filter the full set here so that we only use the relevant 1573\n",
    "for stim_id in stim_ids:\n",
    "    filename = 'img' + str(stim_id) + '.mat'\n",
    "    data = loadmat(os.path.join(PATH_TO_DATA, filename))\n",
    "\n",
    "    img = data['img'][:, :500] # Take leftmost part of the image\n",
    "    rgb_img = np.stack([img] * 3, axis=-1) # Convert grayscale to RGB for SimCLR\n",
    "    tensor = torch.tensor(rgb_img, dtype=torch.float32).permute(2, 0, 1) # Shape (C, H, W)\n",
    "    \n",
    "    # Min-max scale the tensor to [0, 1]\n",
    "    tensor_min = tensor.min()\n",
    "    tensor_max = tensor.max()\n",
    "    tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "\n",
    "    # Clamp to [0, 1] to ensure no outliers due to numerical precision\n",
    "    tensor = torch.clamp(tensor, 0.0, 1.0)\n",
    "\n",
    "    transformed_tensor = transform(tensor) # Normalize and resize for SimCLR\n",
    "    img_tensors.append(transformed_tensor)\n",
    "    labels.append(stim_id)\n",
    "\n",
    "image_dataset = TensorDataset(torch.stack(img_tensors), torch.tensor(labels))\n",
    "\n",
    "images, labels = image_dataset.tensors\n",
    "print(\"Processed image labels (stim id):\", labels[:30])\n",
    "print(\"Stim IDs from neural data:\", stim_ids[:30])\n",
    "print(\"Processed dataset shape:\", images.shape) # (N, C, 96, 96)\n",
    "print(f\"Min pixel value (processed): {torch.min(images)}\")\n",
    "print(f\"Max pixel value (processed): {torch.max(images)}\")\n",
    "\n",
    "# Show a sample of processed images\n",
    "img_grid = torch_utils.make_grid(images[:12], nrow=6, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0).numpy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Processed images: sample')\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "filename = 'img20.mat'\n",
    "data = loadmat(os.path.join(PATH_TO_DATA, filename))\n",
    "img = data['img'][:, :500]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img, cmap='gray')  # Adjust cmap as needed ('viridis', 'jet', etc.)\n",
    "plt.colorbar(label=\"Pixel Intensity\")\n",
    "plt.title(\"Rendered Image\")\n",
    "plt.axis(\"off\")  # Hide axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run images through a pretrained SimCLR model and extract features\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict\n",
    "from torch.utils.data import Dataset\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from collections import defaultdict\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # Base ResNet18 backbone (pretrained=False, because we load custom weights later, from the SimCLR checkpoint file)\n",
    "        self.convnet = torchvision.models.resnet18(pretrained=False)\n",
    "        \n",
    "        # This is the projection head, only needed during training. For downstream tasks it is disposed of\n",
    "        # and the final linear layer output is used (Chen et al., 2020) \n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.intermediate_layers_to_capture =[]\n",
    "        self.intermediate_layer_features = {}\n",
    "        self.num_workers = os.cpu_count()\n",
    "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    def load_pretrained(self):\n",
    "        \"\"\"\n",
    "        Load pretrained SimCLR weights\n",
    "        \"\"\"\n",
    "        base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial17/\"\n",
    "        models_dir = \"../../models\"\n",
    "        pretrained_simclr_filename = \"SimCLR.ckpt\"\n",
    "        pretrained_simclr_path = os.path.join(models_dir, pretrained_simclr_filename)\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "        # Check whether the pretrained model file already exists locally. If not, try downloading it\n",
    "        file_url = base_url + pretrained_simclr_filename\n",
    "        if not os.path.isfile(pretrained_simclr_path):\n",
    "            print(f\"Downloading pretrained SimCLR model {file_url}...\")\n",
    "            try:\n",
    "                urllib.request.urlretrieve(file_url, pretrained_simclr_path)\n",
    "            except HTTPError as e:\n",
    "                print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
    "\n",
    "        print(f\"Already downloaded pretrained model: {file_url}\")\n",
    "\n",
    "        # Load pretrained model\n",
    "        checkpoint = torch.load(pretrained_simclr_path, map_location=self.device)\n",
    "        self.load_state_dict(checkpoint['state_dict'])\n",
    "        self.to(self.device)\n",
    "        self.eval()\n",
    "    \n",
    "    def set_intermediate_layers_to_capture(self, layers):\n",
    "        \"\"\"\n",
    "        Register hooks to capture features from intermediate layers\n",
    "        \"\"\"\n",
    "        # Just check the layers specified are actually in the convnet\n",
    "        top_level_block_layers = [name for name, _ in self.convnet.named_children()]\n",
    "        if not all(layer in top_level_block_layers for layer in layers):\n",
    "            print('You have specified convnet layers that are not top-level blocks - make sure your layer names are valid')\n",
    "        \n",
    "        self.intermediate_layers_to_capture = layers\n",
    "        intermediate_layer_features = {}\n",
    "\n",
    "        def get_hook(layer_name):\n",
    "            def hook(module, input, output):\n",
    "                intermediate_layer_features[layer_name] = output.detach()\n",
    "            return hook\n",
    "\n",
    "        for layer_name in layers:\n",
    "            layer = dict([*self.convnet.named_modules()])[layer_name]\n",
    "            layer.register_forward_hook(get_hook(layer_name))\n",
    "\n",
    "        self.intermediate_layer_features = intermediate_layer_features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, dataset: Dataset) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Run the pretrained SimCLR model on the image data, and capture features from final layer and intermediate layers.\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): A PyTorch Dataset containing input images and labels. The image data should have shape (N, C, H, W)\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: A dictionary containing:\n",
    "                - Intermediate layer features as tensors.\n",
    "                - Final layer features under 'final_layer'.\n",
    "                - Labels under 'labels'.\n",
    "            Features from a given layer has shape (N, F) where N is num images, F is number of features - flattened version of (C, H, W).\n",
    "        \"\"\"\n",
    "        self.convnet.fc = nn.Identity()  # Removing projection head g(.)\n",
    "        self.eval()\n",
    "        self.to(self.device)\n",
    "        \n",
    "        # Encode all images\n",
    "        data_loader = DataLoader(dataset, batch_size=64, num_workers=self.num_workers, shuffle=False, drop_last=False)\n",
    "        feats, labels, intermediate_features = [], [], {layer: [] for layer in self.intermediate_layers_to_capture}\n",
    "\n",
    "        for batch_idx, (batch_imgs, batch_labels) in enumerate(tqdm(data_loader)):\n",
    "            batch_imgs = batch_imgs.to(self.device)\n",
    "            batch_feats = self.convnet(batch_imgs)\n",
    "            \n",
    "            feats.append(batch_feats.detach().cpu())\n",
    "            labels.append(batch_labels)\n",
    "\n",
    "            # Collect intermediate layer outputs\n",
    "            for layer in self.intermediate_layers_to_capture:\n",
    "                # Final linear layer outputs a 2d tensor; but intermediate layers don't, so we flatten them (ready for PCA etc.)\n",
    "                layer_output_flattened = self.intermediate_layer_features[layer].view(self.intermediate_layer_features[layer].size(0), -1) \n",
    "                intermediate_features[layer].append(layer_output_flattened.cpu())\n",
    "        \n",
    "        # Concatenate results for each layer\n",
    "        feats = torch.cat(feats, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        intermediate_features = {layer: torch.cat(intermediate_features[layer], dim=0) for layer in self.intermediate_layers_to_capture}\n",
    "\n",
    "        # Debugging log after concatenation\n",
    "        print(\"✅ Feature extraction complete. Final feature shapes:\")\n",
    "        print(f\"Final layer: {feats.shape}\")\n",
    "        for layer, feature in intermediate_features.items():\n",
    "            print(f\"{layer}: {feature.shape}\")  # Check final stored shape\n",
    "\n",
    "        return {**intermediate_features, 'final_layer': feats, 'labels': labels}\n",
    "\n",
    "intermediate_layers = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "sim_clr = SimCLR()\n",
    "sim_clr.load_pretrained()\n",
    "sim_clr.set_intermediate_layers_to_capture(intermediate_layers)\n",
    "feats = sim_clr.extract_features(image_dataset)\n",
    "\n",
    "for layer in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
    "    if layer in feats:\n",
    "        variance = np.var(feats[layer].numpy())\n",
    "        print(f\"{layer} variance: {variance:.6f}\")\n",
    "\n",
    "# Our original images are grayscale, but SimCLR expects 3-channel RGB input.\n",
    "# To meet this requirement, we duplicated the grayscale values across all three RGB channels.\n",
    "# However, for PCA, we only need a single channel, so we extract just the first channel (Red).\n",
    "flattened_images = images[:, 0, :, :].view(images.shape[0], -1) # shape: [1573, 50176] (1573 images, 224x224 pixels)\n",
    "\n",
    "layer1_feats = feats['layer1'] # Shape: torch.Size([1573, 200704]) (n_images, n_features)\n",
    "layer2_feats = feats['layer2']\n",
    "layer3_feats = feats['layer3']\n",
    "layer4_feats = feats['layer4']\n",
    "final_layer_feats = feats['final_layer'] # Shape: torch.Size([1573, 512])\n",
    "\n",
    "print('flattened_images shape', flattened_images.shape)\n",
    "print('layer1 shape', layer1_feats.shape)\n",
    "print('final layer shape', final_layer_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Predict PC of neural data (separate model predicts each PC), e.g. predict PC1 neural data from features of layer2\n",
    "### 2. Feature visualisation of most important features for PC, for layer, each neuron.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "images_representations = {\n",
    "    'raw_pixels': flattened_images,\n",
    "    'layer1': layer1_feats,\n",
    "    'layer2': layer2_feats,\n",
    "    'layer3': layer3_feats,\n",
    "    'layer4': layer4_feats,\n",
    "    'fc': final_layer_feats,\n",
    "}\n",
    "\n",
    "# ===================================\n",
    "# Filter only the top Y neurons (SRV)\n",
    "# ===================================\n",
    "num_neurons = 500\n",
    "reliable_srv_scores = real_srv_all_neurons[reliable_neuron_indices]\n",
    "sorted_indices = np.argsort(reliable_srv_scores)[::-1]\n",
    "most_reliable_neurons = reliable_neuron_indices[sorted_indices[:num_neurons]]\n",
    "highest_srv_scores = real_srv_all_neurons[most_reliable_neurons]\n",
    "neural_responses = imresps[:, :, most_reliable_neurons]\n",
    "neural_responses_mean = neural_responses.mean(axis=1)\n",
    "\n",
    "assert most_reliable_neurons.shape[0] == num_neurons, \"Mismatch in neuron selection!\"\n",
    "print(\"Dimensionality of neural responses:\", neural_responses_mean.shape)\n",
    "print(\"Top 500 reliable neuron indices:\", most_reliable_neurons[:10])\n",
    "print(\"Corresponding SRV scores:\", highest_srv_scores[:10])\n",
    "print(\"Top 500 neural responses shape:\", neural_responses.shape) # (1573, 2, 500)\n",
    "print(\"Averaged top 500 neural responses shape:\", neural_responses_mean.shape) # (1573, 500)\n",
    "\n",
    "# ===================================\n",
    "# Get PCs of neural data\n",
    "# ===================================\n",
    "pca = PCA(10)\n",
    "neural_data_pcs = pca.fit_transform(neural_responses_mean)\n",
    "pc1_neural_data = neural_data_pcs[:, 0]\n",
    "\n",
    "# ===================================\n",
    "# Regression from image representation to first PC of neural data \n",
    "# ===================================\n",
    "for k in images_representations:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images_representations[k], pc1_neural_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    ridge = Ridge(alpha=1000)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"R^2 Score for {k}: {r2:.4f}\")\n",
    "\n",
    "# R^2 Score for raw_pixels: 0.0029\n",
    "# R^2 Score for layer1_features: 0.4033\n",
    "# R^2 Score for layer2_features: 0.4820\n",
    "# R^2 Score for layer3_features: 0.4715\n",
    "# R^2 Score for layer4_features: 0.3455\n",
    "# R^2 Score for final_layer_features: 0.0675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary of results for each layer\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pc_index = 0 # Index of the principal component to predict\n",
    "\n",
    "results = {}\n",
    "for k in images_representations:\n",
    "    # ================================\n",
    "    # Step 1: Split data into training and test sets\n",
    "    # ================================\n",
    "    X_train, X_test, y_train_full, y_test_full = train_test_split(images_representations[k], neural_responses_mean, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ================================\n",
    "    # Step 2: Fit PCA only on the training set\n",
    "    # ================================\n",
    "    pca = PCA(n_components=10)\n",
    "    y_train_pcs = pca.fit_transform(y_train_full)  # Fit PCA on training neural data\n",
    "    y_test_pcs = pca.transform(y_test_full)  # Transform test neural data\n",
    "\n",
    "    # Extract PC as target variable\n",
    "    y_train = y_train_pcs[:, pc_index] \n",
    "    y_test = y_test_pcs[:, pc_index]\n",
    "\n",
    "    # ================================\n",
    "    # Step 3: Perform Cross-Validation for Ridge Regression\n",
    "    # ================================\n",
    "    alphas = np.array([0.1, 1, 10, 100, 1000, 100000, 1000000])\n",
    "    best_alpha = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "\n",
    "    for alpha in alphas:\n",
    "        ridge = Ridge(alpha=alpha)\n",
    "        scores = cross_val_score(ridge, X_train, y_train, cv=kf, scoring=\"r2\")\n",
    "        mean_score = scores.mean()\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_alpha = alpha\n",
    "\n",
    "    print(f\"Best alpha from CV: {best_alpha:.4f}, Mean CV R²: {best_score:.4f}\")\n",
    "\n",
    "    # ================================\n",
    "    # Step 4: Train Ridge Regression with Best Alpha\n",
    "    # ================================\n",
    "    ridge = Ridge(alpha=best_alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    # ================================\n",
    "    # Step 5: Evaluate Model on Test Set\n",
    "    # ================================\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Test R² Score: {r2:.4f}\")\n",
    "    results.update({k: {\"best_alpha\": best_alpha, \"mean_cv_r2\": best_score, \"test_r2\": r2, \"ridge\": ridge}})\n",
    "\n",
    "    # ================================\n",
    "    # Step 6: Plot Predictions vs True PC1 Values\n",
    "    # ================================\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.xlabel(f\"True PC{pc_index+1} of Neural Data\")\n",
    "    plt.ylabel(f\"Predicted PC{pc_index+1}\")\n",
    "    plt.title(f\"Ridge Regression: {k} → PC{pc_index+1} of Neural Data\")\n",
    "    plt.axline((0, 0), slope=1, color=\"red\", linestyle=\"--\", label=\"Ideal Fit\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot summary of results across all \n",
    "\n",
    "layers = list(results.keys())\n",
    "mean_cv_r2 = [results[layer]['mean_cv_r2'] for layer in layers]\n",
    "test_r2 = [results[layer]['test_r2'] for layer in layers]\n",
    "best_alphas = [results[layer]['best_alpha'] for layer in layers]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bar_width = 0.4\n",
    "x = np.arange(len(layers))\n",
    "bars1 = plt.bar(x - bar_width/2, mean_cv_r2, bar_width, label=\"Mean CV R²\")\n",
    "bars2 = plt.bar(x + bar_width/2, test_r2, bar_width, label=\"Test R² Score\")\n",
    "\n",
    "for i in range(len(layers)):\n",
    "    plt.text(x[i] - bar_width/2, mean_cv_r2[i] + 0.02, f\"α={int(best_alphas[i])}\", \n",
    "             ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "plt.xlabel(\"Feature Representation Layer\")\n",
    "plt.ylabel(\"R² Score\")\n",
    "plt.title(f\"Ridge Regression to PC{pc_index+1} of Neural Data (average response of each of the 500 most stimulus-responsive neurons)\")\n",
    "plt.xticks(ticks=x, labels=layers, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ridge regression feature coefficients\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layers_feats_top_features = {\n",
    "    'raw_pixels': { 'feats': flattened_images, 'top_features': [] },\n",
    "    'layer1': { 'feats': layer1_feats, 'top_features': [] },\n",
    "    'layer2': { 'feats': layer2_feats, 'top_features': [] },\n",
    "    'layer3': { 'feats': layer3_feats, 'top_features': [] },\n",
    "    'layer4': { 'feats': layer4_feats, 'top_features': [] },\n",
    "    'fc': { 'feats': final_layer_feats, 'top_features': [] },\n",
    "}\n",
    "\n",
    "for layer in images_representations:\n",
    "    ridge = results[layer]['ridge']\n",
    "\n",
    "    feature_importance = np.abs(ridge.coef_)\n",
    "    sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "    top_features = sorted_indices[:20] # Select top 20 important features\n",
    "\n",
    "    layers_feats_top_features[layer]['top_features'] = top_features\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(len(top_features)), feature_importance[top_features])\n",
    "    plt.xticks(range(len(top_features)), top_features, rotation=90)\n",
    "    plt.xlabel(\"Feature Index\")\n",
    "    plt.ylabel(\"Absolute Coefficient Magnitude\")\n",
    "    plt.title(f\"[{layer}]: Feature Importance for Predicting PC{pc_index+1} ({layer})\")\n",
    "    plt.show()\n",
    "\n",
    "print(layers_feats_top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature visualization: generate synthetic images optimized to maximally activate a given feature in a given layer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for k in layers_feats_top_features:\n",
    "    if k == 'raw_pixels':\n",
    "        continue\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load pretrained SimCLR model\n",
    "    sim_clr = SimCLR()\n",
    "    sim_clr.load_pretrained()\n",
    "    sim_clr.set_intermediate_layers_to_capture([k])  # Capture layer2 features\n",
    "    sim_clr.eval()\n",
    "    sim_clr.to(device)\n",
    "\n",
    "    # Top neurons (from Ridge regression feature importance analysis)\n",
    "    top_features = layers_feats_top_features[k]['top_features'][:5]\n",
    "\n",
    "    # Optimization settings\n",
    "    num_iterations = 200  # Number of gradient ascent steps\n",
    "    learning_rate = 0.05  # Step size\n",
    "    image_size = 224  # Image resolution\n",
    "\n",
    "    # Create synthetic images\n",
    "    fig, axes = plt.subplots(1, len(top_features), figsize=(15, 5))\n",
    "\n",
    "    # Register hook only once\n",
    "    intermediate_features = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        intermediate_features[k] = output\n",
    "\n",
    "    layer = dict([*sim_clr.convnet.named_modules()])[k]\n",
    "    hook_handle = layer.register_forward_hook(hook_fn)\n",
    "\n",
    "    for i, neuron in enumerate(top_features):\n",
    "        # Start with random noise image\n",
    "        # synthetic_image = torch.randn(1, 3, image_size, image_size, device=device, requires_grad=True)\n",
    "        synthetic_image = torch.randn(1, 1, image_size, image_size, device=device, requires_grad=True) # greyscale\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer = torch.optim.Adam([synthetic_image], lr=learning_rate, weight_decay=1e-6)  # Added weight decay\n",
    "\n",
    "        for _ in range(num_iterations):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Convert grayscale image into 3-channel format for SimCLR input\n",
    "            grayscale_image_3channel = synthetic_image.repeat(1, 3, 1, 1)  # (1, 1, H, W) → (1, 3, H, W)\n",
    "\n",
    "            # Forward pass through SimCLR to extract layer2 features\n",
    "            _ = sim_clr.convnet(grayscale_image_3channel)  # Forward pass\n",
    "            features = intermediate_features[k]  # Get extracted layer2 features\n",
    "\n",
    "            # Ensure neuron index is valid\n",
    "            neuron_idx = min(neuron, features.shape[1] - 1)  # Avoid out-of-range errors\n",
    "            loss = -features[0, neuron_idx].mean()\n",
    "\n",
    "            # Regularization (Total Variation Loss for smooth images)\n",
    "            tv_loss = torch.sum(torch.abs(synthetic_image[:, :, :, :-1] - synthetic_image[:, :, :, 1:])) + \\\n",
    "                    torch.sum(torch.abs(synthetic_image[:, :, :-1, :] - synthetic_image[:, :, 1:, :]))\n",
    "            loss += 0.0001 * tv_loss\n",
    "\n",
    "            # Backpropagation & update image\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Normalize image values\n",
    "            synthetic_image.data = torch.clamp(synthetic_image.data, -1, 1)\n",
    "\n",
    "        # Convert image to NumPy format\n",
    "        # img_np = synthetic_image.detach().cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        img_np = synthetic_image.detach().cpu().squeeze().numpy() # Keep grayscale shape (H, W)\n",
    "        img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())  # Normalize to [0,1]\n",
    "\n",
    "        # Display result\n",
    "        axes[i].imshow(img_np, cmap=\"gray\")\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(f\"Feature {neuron}\")\n",
    "\n",
    "    # Remove hook to prevent memory leak\n",
    "    hook_handle.remove()\n",
    "\n",
    "    fig.suptitle(f\"Feature Visualization for {k} (Features most predictive of PC{pc_index+1} of neural data)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For a given feature from a given layer, show the most activating and least activating images\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(layer4_feats.shape)\n",
    "\n",
    "layer_name = 'layer3'\n",
    "chosen_feature = 181\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sim_clr = SimCLR()\n",
    "sim_clr.load_pretrained()\n",
    "sim_clr.set_intermediate_layers_to_capture([layer_name])\n",
    "sim_clr.eval()\n",
    "sim_clr.to(device)\n",
    "\n",
    "image_activations = []\n",
    "\n",
    "print('IMAGE DATASET LEN:', len(image_dataset))\n",
    "\n",
    "for img_idx, img in enumerate(image_dataset):  \n",
    "    img_tensor = img[0].unsqueeze(0).to(device)\n",
    "    _ = sim_clr.convnet(img_tensor)\n",
    "    features = sim_clr.intermediate_layer_features[layer_name]\n",
    "\n",
    "    # Flatten features to match `layer4_feats.shape`\n",
    "    features = features.view(1, -1)  # (1, 512*3*3) = (1, 4608)\n",
    "\n",
    "    # Get activation of chosen neuron (mean activation across spatial locations)\n",
    "    activation = features[0, chosen_feature].mean().item()\n",
    "    image_activations.append((img_idx, activation))\n",
    "\n",
    "image_activations.sort(key=lambda x: x[1], reverse=True) \n",
    "\n",
    "# Get top 5 and bottom 5 activating images\n",
    "top_images = [image_dataset[i[0]][0] for i in image_activations[:10]] \n",
    "bottom_images = [image_dataset[i[0]][0] for i in image_activations[-10:]]\n",
    "\n",
    "def plot_images(top_images, bottom_images, title):\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))  # 4 rows, 5 columns\n",
    "\n",
    "    # Plot top 10 activating images (first 2 rows)\n",
    "    for i, img in enumerate(top_images):\n",
    "        img_np = img.numpy()[0]  # Take only the first channel (grayscale)\n",
    "        row, col = divmod(i, 5)  # Get row & column index\n",
    "        axes[row, col].imshow(img_np, cmap=\"gray\")\n",
    "        axes[row, col].axis(\"off\")\n",
    "        axes[row, col].set_title(f\"Top {i+1}\")\n",
    "\n",
    "    # Plot bottom 10 activating images (last 2 rows)\n",
    "    for i, img in enumerate(bottom_images):\n",
    "        img_np = img.numpy()[0]  # Take only the first channel (grayscale)\n",
    "        row, col = divmod(i, 5)  # Get row & column index\n",
    "        axes[row + 2, col].imshow(img_np, cmap=\"gray\")  # Offset by 2 rows\n",
    "        axes[row + 2, col].axis(\"off\")\n",
    "        axes[row + 2, col].set_title(f\"Bottom {i+1}\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_images(top_images, bottom_images, f\"Top & Bottom Activating Images for Feature {chosen_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at how the mouse visual cortex neurons respond to certain images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print('IMAGE DATASET LEN:', len(image_dataset))\n",
    "\n",
    "# Get the top 10 image indexes based on the sorted activations, and plot images\n",
    "top_indices = [img_idx for img_idx, _ in image_activations[:10]]\n",
    "bottom_indices = [img_idx for img_idx, _ in image_activations[-10:]]\n",
    "print(\"Top activating image indexes:\", top_indices)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, idx in enumerate(top_indices):\n",
    "    img_tensor = image_dataset[idx][0]\n",
    "    img_np = img_tensor.numpy()[0]\n",
    "    \n",
    "    row, col = divmod(i, 5)\n",
    "    axes[row, col].imshow(img_np, cmap=\"gray\")\n",
    "    axes[row, col].axis(\"off\")\n",
    "    axes[row, col].set_title(f\"Idx {idx}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### We want to plot the average neural response of each neuron to the top 10 activating images vs. non-activating images vs. bottom 10 activating images vs. all images\n",
    "\n",
    "print('NEURAL RESPONSES SHAPE:', neural_responses.shape)\n",
    "\n",
    "# Extract neural responses for flying bird images\n",
    "flying_bird_responses = neural_responses[top_indices, :] # shape: (num_flying_bird_images, num_neurons)\n",
    "\n",
    "print('FLYING BIRD RESPONSES SHAPE:', flying_bird_responses.shape)\n",
    "\n",
    "# Compute the average response of each neuron across the flying bird images\n",
    "avg_responses = flying_bird_responses.mean(axis=(0, 1))  # shape becomes (500,)\n",
    "\n",
    "print('AVERAGE RESPONSES SHAPE:', avg_responses.shape)\n",
    "\n",
    "# Optionally, compute the average response for non-flying bird images for comparison:\n",
    "all_indices = np.arange(len(image_dataset))\n",
    "non_bird_indices = np.setdiff1d(all_indices, top_indices)\n",
    "non_bird_responses = neural_responses[non_bird_indices, :]\n",
    "avg_responses_non_bird = non_bird_responses.mean(axis=(0, 1))  # shape becomes (500,)\n",
    "\n",
    "bottom_images_responses = neural_responses[bottom_indices]\n",
    "avg_bottom_responses = bottom_images_responses.mean(axis=(0, 1))\n",
    "\n",
    "num_neurons = avg_responses.shape[0] # should be 500\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(num_neurons), avg_responses, color='green')\n",
    "plt.xlabel(\"Neuron Index\")\n",
    "plt.ylabel(\"Average Neural Response\")\n",
    "plt.title(\"Average Response to Flying Bird Images\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(num_neurons), avg_responses_non_bird, color='gray')\n",
    "plt.xlabel(\"Neuron Index\")\n",
    "plt.ylabel(\"Average Neural Response\")\n",
    "plt.title(\"Average Response to Non-Bird Images\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(np.arange(num_neurons), avg_responses, color='green', label=\"Top 10 Activating Images\")\n",
    "plt.plot(np.arange(num_neurons), avg_bottom_responses, color='red', label=\"Bottom 10 Activating Images\")\n",
    "plt.plot(np.arange(num_neurons), neural_responses.mean(axis=(0, 1)), color='blue', label=\"All Images\")\n",
    "plt.xlabel(\"Neuron Index\")\n",
    "plt.ylabel(\"Average Neural Response\")\n",
    "plt.title(\"Average Neural Response: Overlay of Flying Bird vs. Non-Bird Images\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
