{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Load data\n",
    "\n",
    "# imresps.npy is of shape (1573, 2, 15363), where 1573 is number of images, 2 repeats each, and 15363 neurons recorded\n",
    "# stimids.npy has the image id (matching the image dataset ~selection1866~) for each stimulus number, \n",
    "# so of you want to see what image was presented on imresps[502] you would check stim_ids[502]\n",
    "\n",
    "PATH_TO_DATA = '../../data/neural'\n",
    "\n",
    "imresps = np.load(path.join(PATH_TO_DATA, 'imresps.npy'))\n",
    "stimids = np.load(path.join(PATH_TO_DATA, 'stimids.npy'))\n",
    "\n",
    "print(imresps.shape) # (1573, 2, 15363)\n",
    "print(stimids.shape) # (1573,)\n",
    "\n",
    "### Compute the null distribution of SRV values for all neurons\n",
    "\n",
    "def compute_signal_related_variance(resp_a, resp_b, mean_center=True):\n",
    "    \"\"\"\n",
    "    compute the fraction of signal-related variance for each neuron,\n",
    "    as per Stringer et al Nature 2019. Cross-validated by splitting\n",
    "    responses into two halves. Note, this only is \"correct\" if resp_a\n",
    "    and resp_b are *not* averages of many trials.\n",
    "\n",
    "    Args:\n",
    "        resp_a (ndarray): n_stimuli, n_cells\n",
    "        resp_b (ndarray): n_stimuli, n_cells\n",
    "\n",
    "    Returns:\n",
    "        fraction_of_stimulus_variance: 0-1, 0 is non-stimulus-caring, 1 is only-stimulus-caring neurons\n",
    "        stim_to_noise_ratio: ratio of the stim-related variance to all other variance\n",
    "    \"\"\"\n",
    "    if len(resp_a.shape) > 2:\n",
    "        # if the stimulus is multi-dimensional, flatten across all stimuli\n",
    "        resp_a = resp_a.reshape(-1, resp_a.shape[-1])\n",
    "        resp_b = resp_b.reshape(-1, resp_b.shape[-1])\n",
    "    ns, nc = resp_a.shape\n",
    "    if mean_center:\n",
    "        # mean-center the activity of each cell\n",
    "        resp_a = resp_a - resp_a.mean(axis=0)\n",
    "        resp_b = resp_b - resp_b.mean(axis=0)\n",
    "    \n",
    "    # compute the cross-trial stimulus covariance of each cell\n",
    "    # dot-product each cell's (n_stim, ) vector from one half\n",
    "    # with its own (n_stim, ) vector on the other half\n",
    "\n",
    "    covariance = (resp_a * resp_b).sum(axis=0) / ns\n",
    "\n",
    "    # compute the variance of each cell across both halves\n",
    "    resp_a_variance = (resp_a**2).sum(axis=0) / ns\n",
    "    resp_b_variance = (resp_b**2).sum(axis=0) / ns\n",
    "    total_variance = (resp_a_variance + resp_b_variance) / 2\n",
    "\n",
    "    if np.any(total_variance < 1e-12):\n",
    "        print(f\"Warning: Near-zero total variance for neurons: {np.where(total_variance < 1e-12)[0]}\")\n",
    "\n",
    "    # compute the fraction of the total variance that is\n",
    "    # captured in the covariance\n",
    "    fraction_of_stimulus_variance = covariance / total_variance\n",
    "\n",
    "    # if you want, you can compute SNR as well:\n",
    "    stim_to_noise_ratio = fraction_of_stimulus_variance / (\n",
    "        1 - fraction_of_stimulus_variance\n",
    "    )\n",
    "\n",
    "    return fraction_of_stimulus_variance, stim_to_noise_ratio\n",
    "\n",
    "# TODO: double check INDEXING (images, cells)\n",
    "\n",
    "# imresps shape = (1573, 2, 15363)\n",
    "# responses in imresps shape = (2, 15363)\n",
    "num_stimuli = imresps.shape[0] # 1573\n",
    "num_repeats = imresps.shape[1] # 2\n",
    "num_neurons = imresps.shape[2] # 15363\n",
    "n_shuffles = 100\n",
    "\n",
    "null_srv_all_neurons = [] # shape (n_shuffles, num_neurons)\n",
    "\n",
    "for _ in range(n_shuffles):\n",
    "    # Shuffle stimulus indices *twice* to create two independent splits!\n",
    "    shuffled_indices_A = np.random.permutation(num_stimuli)\n",
    "    shuffled_indices_B = np.random.permutation(num_stimuli)\n",
    "\n",
    "    # Now for the splits, we can just use fixed repeat indices, \n",
    "    # because for each split, at index N the responses correspond to different stimuli\n",
    "    # e.g. split_A = [ stim_100_repeat_1, stim_2_repeat_1, stim_19_repeat_1, ... ]\n",
    "    # e.g. split_B = [ stim_543_repeat_2, stim_345_repeat_2, stim_3_repeat_2, ... ]\n",
    "    split_A = imresps[shuffled_indices_A, 0, :]\n",
    "    split_B = imresps[shuffled_indices_B, 1, :]\n",
    "\n",
    "    # Compute SRV for the shuffled data\n",
    "    fraction_of_stimulus_variance, _ = compute_signal_related_variance(split_A, split_B)\n",
    "    null_srv_all_neurons.append(fraction_of_stimulus_variance)\n",
    "\n",
    "null_srv_all_neurons = np.array(null_srv_all_neurons)\n",
    "null_srv_all_neurons.shape # (100, 15363)\n",
    "\n",
    "print(null_srv_all_neurons[0])\n",
    "print(null_srv_all_neurons[33])\n",
    "\n",
    "# e.g. if neuron_index = 0, it will plot the SRV value for neuron 0 across all shuffles\n",
    "neuron_index = 0\n",
    "plt.hist([srv[neuron_index] for srv in null_srv_all_neurons], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()\n",
    "\n",
    "### Compute the real SRV for each neuron\n",
    "\n",
    "# TODO: Question for Ali: why can't we just split like this?\n",
    "# split_A_real = imresps[:, 0, :] # First repeat for each stimulus\n",
    "# split_B_real = imresps[:, 1, :] # Second repeat for each stimulus\n",
    "\n",
    "split_A, split_B = [], []\n",
    "for responses in imresps: # responses shape: (2, n_neurons)\n",
    "    indices = np.random.permutation(2) # Randomly shuffle [0, 1]\n",
    "    split_A.append(responses[indices[0]]) # Assign one repeat to split_A\n",
    "    split_B.append(responses[indices[1]]) # Assign the other to split_B\n",
    "\n",
    "split_A = np.array(split_A)  # Shape: (n_stimuli, n_neurons)\n",
    "split_B = np.array(split_B)  # Shape: (n_stimuli, n_neurons)\n",
    "\n",
    "# Compute SRV for real data\n",
    "real_srv_all_neurons, stim_to_noise_ratio = compute_signal_related_variance(split_A, split_B)\n",
    "\n",
    "print(real_srv_all_neurons)\n",
    "print(stim_to_noise_ratio)\n",
    "\n",
    "print(\"Real SRV shape:\", real_srv_all_neurons.shape) # Should be (15363,)\n",
    "\n",
    "plt.hist(real_srv_all_neurons, bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()\n",
    "\n",
    "### Filter neurons whose real SRV is in the top 90th percentile of its null distribution\n",
    "\n",
    "# This gives the 90th-percentile SRV value of the null distribution for each neuron\n",
    "# In other words the threshold for each neuron to be considered reliable\n",
    "# e.g. if neuron 0 has a null distribution of SRVs across 10 shuffles \n",
    "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], the threshold would be 0.9\n",
    "top_99th_percentile_null = np.percentile(null_srv_all_neurons, 99, axis=0)\n",
    "print(top_99th_percentile_null) # [0.03651716 0.03126347 0.03325775 ... 0.02738261 0.03546677 0.0333109 ]\n",
    "\n",
    "# Get indices of reliable neurons\n",
    "reliable_neuron_indices = np.where(real_srv_all_neurons >= top_99th_percentile_null)[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of reliable neurons: {len(reliable_neuron_indices)}\") # 5654\n",
    "print(f\"Indices of reliable neurons: {reliable_neuron_indices}\") # [   14    29    48 ... 15357 15358 15360]\n",
    "\n",
    "plt.hist(real_srv_all_neurons, bins=100, color='red', alpha=0.7)\n",
    "plt.hist(real_srv_all_neurons[reliable_neuron_indices], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(\"All Neurons: SRV all vs. SRV reliable\")\n",
    "plt.show()\n",
    "\n",
    "# Gather the neural responses for the reliable neurons\n",
    "# we take the average across repeats for each neuron\n",
    "neural_responses = imresps[:, :, reliable_neuron_indices] # Shape: (1573, 2, 5654)\n",
    "neural_responses_mean = neural_responses.mean(axis=1) # Shape: (1573, 5654) -> 1573 images, 5654 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and preprocess images\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.transforms import Normalize, Compose, Resize, CenterCrop, ToTensor\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import utils as torch_utils\n",
    " \n",
    "PATH_TO_DATA = '../../data/selection1866'\n",
    "\n",
    "file_list = sorted(f for f in os.listdir(PATH_TO_DATA) if f.endswith('.mat'))\n",
    "stim_ids = stimids.astype(int)\n",
    "\n",
    "print(stim_ids)\n",
    "print(stimids)\n",
    "\n",
    "transform = Compose([\n",
    "    Resize(244), # Resize shortest edge to 224 (cut off the rightmost part of the image)\n",
    "    CenterCrop((224, 224)),\n",
    "    ToTensor(), # Convert to torch.Tensor with range [0,1]\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
    "])\n",
    "\n",
    "img_tensors, labels = [], []\n",
    "\n",
    "print('List:', file_list)\n",
    "\n",
    "# we have 1866 images here, but the neural response data only uses 1573 of them\n",
    "# because some ~300 images didn't have two repeats, so were disposed\n",
    "# therefore we filter the full set here so that we only use the relevant 1573\n",
    "for stim_id in stim_ids:\n",
    "    filename = 'img' + str(stim_id) + '.mat'\n",
    "    data = loadmat(os.path.join(PATH_TO_DATA, filename))\n",
    "\n",
    "    img = data['img'][:, :500] # Take leftmost part of the image\n",
    "    rgb_img = np.stack([img] * 3, axis=-1) # Convert grayscale to RGB for SimCLR\n",
    "    tensor = torch.tensor(rgb_img, dtype=torch.float32).permute(2, 0, 1) # Shape (C, H, W)\n",
    "    \n",
    "    # # Min-max scale the tensor to [0, 1]\n",
    "    # tensor_min = tensor.min()\n",
    "    # tensor_max = tensor.max()\n",
    "    # tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "\n",
    "    # # Clamp to [0, 1] to ensure no outliers due to numerical precision\n",
    "    # tensor = torch.clamp(tensor, 0.0, 1.0)\n",
    "\n",
    "    tensor = tensor / 255.0 # Scale from [0,255] to [0,1] **(instead of per-image min-max scaling)**\n",
    "\n",
    "    img_tensors.append(tensor)\n",
    "    labels.append(stim_id)\n",
    "\n",
    "image_dataset = TensorDataset(torch.stack(img_tensors), torch.tensor(labels))\n",
    "\n",
    "images, labels = image_dataset.tensors\n",
    "print(\"Labels:\", labels[:10])\n",
    "print(\"Processed dataset shape:\", images.shape) # (N, C, 96, 96)\n",
    "print(f\"Min pixel value (processed): {torch.min(images)}\")\n",
    "print(f\"Max pixel value (processed): {torch.max(images)}\")\n",
    "\n",
    "# Show a sample of processed images\n",
    "img_grid = torch_utils.make_grid(images[:12], nrow=6, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0).numpy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Processed images: sample')\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the pretrained VGG-19 model\n",
    "vgg19 = torchvision.models.vgg19(pretrained=True).features.eval()\n",
    "\n",
    "layers_to_capture = {\n",
    "    # \"conv1_1\": 0, \"conv1_2\": 2,\n",
    "    # \"conv2_1\": 5, \"conv2_2\": 7,\n",
    "    \"conv3_1\": 10,\n",
    "    # \"conv3_2\": 12, \"conv3_3\": 14, \"conv3_4\": 16,\n",
    "    # \"conv4_1\": 19, \"conv4_2\": 21, \"conv4_3\": 23, \"conv4_4\": 25,\n",
    "    # \"conv5_1\": 28, \"conv5_2\": 30, \"conv5_3\": 32, \"conv5_4\": 34\n",
    "}\n",
    "\n",
    "activations = {}\n",
    "\n",
    "def hook_fn(layer_name):\n",
    "    def hook(module, input, output):\n",
    "        activations[layer_name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register hooks\n",
    "for layer_name, layer_idx in layers_to_capture.items():\n",
    "    vgg19[layer_idx].register_forward_hook(hook_fn(layer_name))\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_vgg_features(dataset, batch_size=16):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    feature_maps = {layer: [] for layer in layers_to_capture}\n",
    "    labels = []\n",
    "    \n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        _ = vgg19(batch_imgs) # Forward pass to trigger hooks\n",
    "        \n",
    "        for layer in layers_to_capture:\n",
    "            feature_maps[layer].append(activations[layer].cpu())\n",
    "        \n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    # Concatenate features across all batches\n",
    "    feature_maps = {layer: torch.cat(feature_maps[layer], dim=0) for layer in feature_maps}\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    return feature_maps, labels\n",
    "\n",
    "# Run feature extraction\n",
    "vgg_features, vgg_labels = extract_vgg_features(image_dataset)\n",
    "\n",
    "# Flatten each feature map into shape (N, F), where F = C * H * W\n",
    "vgg_features_flat = {layer: vgg_features[layer].view(vgg_features[layer].size(0), -1) for layer in vgg_features}\n",
    "\n",
    "# print(\"conv4_1 before flatten:\", vgg_features[\"conv4_1\"].shape)  # Example: [1573, 512, 14, 14]\n",
    "# print(\"conv4_1 after flatten:\", vgg_features_flat[\"conv4_1\"].shape)  # Example: [1573, 100352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 100  # Try 50, 100, 200\n",
    "\n",
    "# Example using conv4_1\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca = pca.fit_transform(vgg_features_flat[\"conv3_1\"])\n",
    "\n",
    "# Split into train-test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, neural_responses_mean, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Train regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "# Compute R² scores\n",
    "r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(f\"R² using conv4_1 with {num_components} PCs:\", r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute correlation between each principal component and each neuron's response\n",
    "corr_matrix = np.corrcoef(X_train.T, Y_train.T)[:X_train.shape[1], X_train.shape[1]:]\n",
    "\n",
    "mean_corr = np.abs(corr_matrix).mean()\n",
    "print(f\"Mean absolute correlation: {mean_corr:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for layer in [\"conv2_1\", \"conv3_1\", \"conv4_1\", \"conv5_1\"]:\n",
    "    layer_activations = vgg_features[layer]\n",
    "    N, C, H, W = layer_activations.shape\n",
    "    layer_activations_flat = layer_activations.view(N, -1).numpy()\n",
    "    \n",
    "    pca = PCA(n_components=50)\n",
    "    X_pca = pca.fit_transform(layer_activations_flat)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_pca, neural_responses_mean, test_size=0.2, random_state=42)\n",
    "    reg = Ridge(alpha=10)\n",
    "    reg.fit(X_train, Y_train)\n",
    "    \n",
    "    r2_scores = r2_score(Y_test, reg.predict(X_test), multioutput='raw_values')\n",
    "    print(f\"Layer {layer}: Mean R² = {r2_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Why are the regression performing poorly even for VGG-19 (Cadena et al. + Kenneth found it yielded 30%-50% explained variance)\n",
    "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check image indexing and ordering\n",
    "\n",
    "# 1. Check the Order of stimids and Image Files\n",
    "print(\"First 10 `stimids` entries:\", stimids[:10])\n",
    "print(\"First 10 image filenames used:\", [f'img{stim_id}.mat' for stim_id in stimids[:10]])\n",
    "\n",
    "# First 10 `stimids` entries: [ 1.  2.  3.  4.  5.  7.  8.  9. 10. 11.]\n",
    "# First 10 image filenames used: ['img1.0.mat', 'img2.0.mat', 'img3.0.mat', 'img4.0.mat', 'img5.0.mat', 'img7.0.mat', 'img8.0.mat', 'img9.0.mat', 'img10.0.mat', 'img11.0.mat']\n",
    "\n",
    "# 2. Check Feature Map Ordering Before PCA\n",
    "print(\"First 15 image labels in dataset:\", [labels[i].item() for i in range(15)])\n",
    "print(\"First 15 images used for neural data:\", stimids[:15])\n",
    "\n",
    "# First 5 image labels in dataset: [1, 2, 3, 4, 5]\n",
    "# First 5 images used for neural data: [1. 2. 3. 4. 5.]\n",
    "\n",
    "# 3. Check Neural Response Alignment\n",
    "print(\"Shape of neural_responses_mean:\", neural_responses_mean.shape)  # (1573, 5654)\n",
    "print(\"First 15 entries of `stimids`:\", stimids[:15])\n",
    "print(\"First 15 images passed to VGG:\", labels[:15].numpy())\n",
    "\n",
    "# First 15 entries of `stimids`: [ 1.  2.  3.  4.  5.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
    "# First 15 images passed to VGG: [ 1  2  3  4  5  7  8  9 10 11 12 13 14 15 16]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
