{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.1. Load data\n",
    "\n",
    "# imresps.npy is of shape (1573, 2, 15363), where 1573 is number of images, 2 repeats each, and 15363 neurons recorded\n",
    "# stimids.npy has the image id (matching the image dataset ~selection1866~) for each stimulus number, \n",
    "# so of you want to see what image was presented on imresps[502] you would check stim_ids[502]\n",
    "\n",
    "PATH_TO_DATA = '../../data/neural'\n",
    "\n",
    "imresps = np.load(path.join(PATH_TO_DATA, 'imresps.npy'))\n",
    "stimids = np.load(path.join(PATH_TO_DATA, 'stimids.npy'))\n",
    "\n",
    "print(imresps.shape) # (1573, 2, 15363)\n",
    "print(stimids.shape) # (1573,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signal_related_variance(resp_a, resp_b, mean_center=True):\n",
    "    \"\"\"\n",
    "    compute the fraction of signal-related variance for each neuron,\n",
    "    as per Stringer et al Nature 2019. Cross-validated by splitting\n",
    "    responses into two halves. Note, this only is \"correct\" if resp_a\n",
    "    and resp_b are *not* averages of many trials.\n",
    "\n",
    "    Args:\n",
    "        resp_a (ndarray): n_stimuli, n_cells\n",
    "        resp_b (ndarray): n_stimuli, n_cells\n",
    "\n",
    "    Returns:\n",
    "        fraction_of_stimulus_variance: 0-1, 0 is non-stimulus-caring, 1 is only-stimulus-caring neurons\n",
    "        stim_to_noise_ratio: ratio of the stim-related variance to all other variance\n",
    "    \"\"\"\n",
    "    if len(resp_a.shape) > 2:\n",
    "        # if the stimulus is multi-dimensional, flatten across all stimuli\n",
    "        resp_a = resp_a.reshape(-1, resp_a.shape[-1])\n",
    "        resp_b = resp_b.reshape(-1, resp_b.shape[-1])\n",
    "    ns, nc = resp_a.shape\n",
    "    if mean_center:\n",
    "        # mean-center the activity of each cell\n",
    "        resp_a = resp_a - resp_a.mean(axis=0)\n",
    "        resp_b = resp_b - resp_b.mean(axis=0)\n",
    "    \n",
    "    # compute the cross-trial stimulus covariance of each cell\n",
    "    # dot-product each cell's (n_stim, ) vector from one half\n",
    "    # with its own (n_stim, ) vector on the other half\n",
    "\n",
    "    covariance = (resp_a * resp_b).sum(axis=0) / ns\n",
    "\n",
    "    # compute the variance of each cell across both halves\n",
    "    resp_a_variance = (resp_a**2).sum(axis=0) / ns\n",
    "    resp_b_variance = (resp_b**2).sum(axis=0) / ns\n",
    "    total_variance = (resp_a_variance + resp_b_variance) / 2\n",
    "\n",
    "    if np.any(total_variance < 1e-12):\n",
    "        print(f\"Warning: Near-zero total variance for neurons: {np.where(total_variance < 1e-12)[0]}\")\n",
    "\n",
    "    # compute the fraction of the total variance that is\n",
    "    # captured in the covariance\n",
    "    fraction_of_stimulus_variance = covariance / total_variance\n",
    "\n",
    "    # if you want, you can compute SNR as well:\n",
    "    stim_to_noise_ratio = fraction_of_stimulus_variance / (\n",
    "        1 - fraction_of_stimulus_variance\n",
    "    )\n",
    "\n",
    "    return fraction_of_stimulus_variance, stim_to_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1. Compute the null distribution of SRV values for all neurons\n",
    "\n",
    "# TODO: double check INDEXING (images, cells)\n",
    "\n",
    "# imresps shape = (1573, 2, 15363)\n",
    "# responses in imresps shape = (2, 15363)\n",
    "num_stimuli = imresps.shape[0] # 1573\n",
    "num_repeats = imresps.shape[1] # 2\n",
    "num_neurons = imresps.shape[2] # 15363\n",
    "n_shuffles = 100\n",
    "\n",
    "null_srv_all_neurons = [] # shape (n_shuffles, num_neurons)\n",
    "\n",
    "for _ in range(n_shuffles):\n",
    "    # Shuffle stimulus indices *twice* to create two independent splits!\n",
    "    shuffled_indices_A = np.random.permutation(num_stimuli)\n",
    "    shuffled_indices_B = np.random.permutation(num_stimuli)\n",
    "\n",
    "    # Now for the splits, we can just use fixed repeat indices, \n",
    "    # because for each split, at index N the responses correspond to different stimuli\n",
    "    # e.g. split_A = [ stim_100_repeat_1, stim_2_repeat_1, stim_19_repeat_1, ... ]\n",
    "    # e.g. split_B = [ stim_543_repeat_2, stim_345_repeat_2, stim_3_repeat_2, ... ]\n",
    "    split_A = imresps[shuffled_indices_A, 0, :]\n",
    "    split_B = imresps[shuffled_indices_B, 1, :]\n",
    "\n",
    "    # Compute SRV for the shuffled data\n",
    "    fraction_of_stimulus_variance, _ = compute_signal_related_variance(split_A, split_B)\n",
    "    null_srv_all_neurons.append(fraction_of_stimulus_variance)\n",
    "\n",
    "null_srv_all_neurons = np.array(null_srv_all_neurons)\n",
    "null_srv_all_neurons.shape # (100, 15363)\n",
    "\n",
    "print(null_srv_all_neurons[0])\n",
    "print(null_srv_all_neurons[33])\n",
    "\n",
    "# e.g. if neuron_index = 0, it will plot the SRV value for neuron 0 across all shuffles\n",
    "neuron_index = 0\n",
    "plt.hist([srv[neuron_index] for srv in null_srv_all_neurons], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2. Compute the real SRV for each neuron\n",
    "\n",
    "# TODO: Question for Ali: why can't we just split like this?\n",
    "# split_A_real = imresps[:, 0, :] # First repeat for each stimulus\n",
    "# split_B_real = imresps[:, 1, :] # Second repeat for each stimulus\n",
    "\n",
    "split_A, split_B = [], []\n",
    "for responses in imresps: # responses shape: (2, n_neurons)\n",
    "    indices = np.random.permutation(2) # Randomly shuffle [0, 1]\n",
    "    split_A.append(responses[indices[0]]) # Assign one repeat to split_A\n",
    "    split_B.append(responses[indices[1]]) # Assign the other to split_B\n",
    "\n",
    "split_A = np.array(split_A)  # Shape: (n_stimuli, n_neurons)\n",
    "split_B = np.array(split_B)  # Shape: (n_stimuli, n_neurons)\n",
    "\n",
    "# Compute SRV for real data\n",
    "real_srv_all_neurons, stim_to_noise_ratio = compute_signal_related_variance(split_A, split_B)\n",
    "\n",
    "print(real_srv_all_neurons)\n",
    "print(stim_to_noise_ratio)\n",
    "\n",
    "print(\"Real SRV shape:\", real_srv_all_neurons.shape) # Should be (15363,)\n",
    "\n",
    "plt.hist(real_srv_all_neurons, bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3. Filter neurons whose real SRV is in the top 90th percentile of its null distribution\n",
    "\n",
    "# This gives the 90th-percentile SRV value of the null distribution for each neuron\n",
    "# In other words the threshold for each neuron to be considered reliable\n",
    "# e.g. if neuron 0 has a null distribution of SRVs across 10 shuffles \n",
    "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], the threshold would be 0.9\n",
    "top_99th_percentile_null = np.percentile(null_srv_all_neurons, 99, axis=0)\n",
    "print(top_99th_percentile_null) # [0.03651716 0.03126347 0.03325775 ... 0.02738261 0.03546677 0.0333109 ]\n",
    "\n",
    "# Get indices of reliable neurons\n",
    "reliable_neuron_indices = np.where(real_srv_all_neurons >= top_99th_percentile_null)[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of reliable neurons: {len(reliable_neuron_indices)}\") # 5654\n",
    "print(f\"Indices of reliable neurons: {reliable_neuron_indices}\") # [   14    29    48 ... 15357 15358 15360]\n",
    "\n",
    "plt.hist(real_srv_all_neurons, bins=100, color='red', alpha=0.7)\n",
    "plt.hist(real_srv_all_neurons[reliable_neuron_indices], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(\"All Neurons: SRV all vs. SRV reliable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.1. Load and preprocess images\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.transforms import Normalize, Compose, Resize, CenterCrop\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import utils as torch_utils\n",
    " \n",
    "PATH_TO_DATA = '../../data/selection1866'\n",
    "\n",
    "file_list = sorted(f for f in os.listdir(PATH_TO_DATA) if f.endswith('.mat'))\n",
    "stim_ids = stimids.astype(int)\n",
    "\n",
    "print(stim_ids)\n",
    "print(stimids)\n",
    "\n",
    "# TODO: run tile 1 and 2 through model separately + concat feature reps (no crop, pad)\n",
    "transform = Compose([\n",
    "    Resize(96), # Resize shortest edge to 96 (cut off the rightmost part of the image)\n",
    "    CenterCrop((96, 96)), # Crop to (96, 96)\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # !! Normalize expects input is already in the range [0, 1]\n",
    "])\n",
    "\n",
    "img_tensors, labels = [], []\n",
    "\n",
    "print('List:', file_list)\n",
    "\n",
    "# we have 1866 images here, but the neural response data only uses 1573 of them\n",
    "# because some ~300 images didn't have two repeats, so were disposed\n",
    "# therefore we filter the full set here so that we only use the relevant 1573\n",
    "for stim_id in stim_ids:\n",
    "    filename = 'img' + str(stim_id) + '.mat'\n",
    "    data = loadmat(os.path.join(PATH_TO_DATA, filename))\n",
    "\n",
    "    img = data['img'][:, :500] # Take leftmost part of the image\n",
    "    rgb_img = np.stack([img] * 3, axis=-1) # Convert grayscale to RGB for SimCLR\n",
    "    tensor = torch.tensor(rgb_img, dtype=torch.float32).permute(2, 0, 1) # Shape (C, H, W)\n",
    "    \n",
    "    # Min-max scale the tensor to [0, 1]\n",
    "    tensor_min = tensor.min()\n",
    "    tensor_max = tensor.max()\n",
    "    tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "\n",
    "    # Clamp to [0, 1] to ensure no outliers due to numerical precision\n",
    "    tensor = torch.clamp(tensor, 0.0, 1.0)\n",
    "\n",
    "    transformed_tensor = transform(tensor) # Normalize and resize for SimCLR\n",
    "    img_tensors.append(transformed_tensor)\n",
    "    labels.append(stim_id)\n",
    "\n",
    "image_dataset = TensorDataset(torch.stack(img_tensors), torch.tensor(labels))\n",
    "\n",
    "images, labels = image_dataset.tensors\n",
    "print(\"Labels:\", labels[:10])\n",
    "print(\"Processed dataset shape:\", images.shape) # (N, C, 96, 96)\n",
    "print(f\"Min pixel value (processed): {torch.min(images)}\")\n",
    "print(f\"Max pixel value (processed): {torch.max(images)}\")\n",
    "\n",
    "# Show a sample of processed images\n",
    "img_grid = torch_utils.make_grid(images[:12], nrow=6, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0).numpy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Processed images: sample')\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.2. Run images through a pretrained SimCLR model and extract features\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict\n",
    "from torch.utils.data import Dataset\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # Base ResNet18 backbone (pretrained=False, because we load custom weights later, from the SimCLR checkpoint file)\n",
    "        self.convnet = torchvision.models.resnet18(pretrained=False)\n",
    "        \n",
    "        # This is the projection head, only needed during training. For downstream tasks it is disposed of\n",
    "        # and the final linear layer output is used (Chen et al., 2020) \n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.intermediate_layers_to_capture =[]\n",
    "        self.intermediate_layer_features = {}\n",
    "        self.num_workers = os.cpu_count()\n",
    "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    def load_pretrained(self):\n",
    "        \"\"\"\n",
    "        Load pretrained SimCLR weights\n",
    "        \"\"\"\n",
    "        base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial17/\"\n",
    "        models_dir = \"../../models\"\n",
    "        pretrained_simclr_filename = \"SimCLR.ckpt\"\n",
    "        pretrained_simclr_path = os.path.join(models_dir, pretrained_simclr_filename)\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "        # Check whether the pretrained model file already exists locally. If not, try downloading it\n",
    "        file_url = base_url + pretrained_simclr_filename\n",
    "        if not os.path.isfile(pretrained_simclr_path):\n",
    "            print(f\"Downloading pretrained SimCLR model {file_url}...\")\n",
    "            try:\n",
    "                urllib.request.urlretrieve(file_url, pretrained_simclr_path)\n",
    "            except HTTPError as e:\n",
    "                print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
    "\n",
    "        print(f\"Already downloaded pretrained model: {file_url}\")\n",
    "\n",
    "        # Load pretrained model\n",
    "        checkpoint = torch.load(pretrained_simclr_path, map_location=self.device)\n",
    "        self.load_state_dict(checkpoint['state_dict'])\n",
    "        self.to(self.device)\n",
    "        self.eval()\n",
    "\n",
    "    def set_intermediate_layers_to_capture(self, layers):\n",
    "        \"\"\"\n",
    "        Register hooks to capture features from intermediate layers\n",
    "        \"\"\"\n",
    "        # Just check the layers specified are actually in the convnet\n",
    "        top_level_block_layers = [name for name, _ in self.convnet.named_children()]\n",
    "        if not all(layer in top_level_block_layers for layer in layers):\n",
    "            print('You have specified convnet layers that are not top-level blocks - make sure your layer names are valid')\n",
    "        \n",
    "        self.intermediate_layers_to_capture = layers\n",
    "        intermediate_layer_features = {}\n",
    "\n",
    "        def get_hook(layer_name):\n",
    "            def hook(module, input, output):\n",
    "                intermediate_layer_features[layer_name] = output.detach()\n",
    "            return hook\n",
    "\n",
    "        for layer_name in layers:\n",
    "            layer = dict([*self.convnet.named_modules()])[layer_name]\n",
    "            layer.register_forward_hook(get_hook(layer_name))\n",
    "\n",
    "        self.intermediate_layer_features = intermediate_layer_features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, dataset: Dataset) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Run the pretrained SimCLR model on the image data, and capture features from final layer and intermediate layers.\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): A PyTorch Dataset containing input images and labels. The image data should have shape (N, C, H, W)\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: A dictionary containing:\n",
    "                - Intermediate layer features as tensors.\n",
    "                - Final layer features under 'final_layer'.\n",
    "                - Labels under 'labels'.\n",
    "            Features from a given layer has shape (N, F) where N is num images, F is number of features - flattened version of (C, H, W).\n",
    "        \"\"\"\n",
    "        self.convnet.fc = nn.Identity()  # Removing projection head g(.)\n",
    "        self.eval()\n",
    "        self.to(self.device)\n",
    "        \n",
    "        # Encode all images\n",
    "        data_loader = DataLoader(dataset, batch_size=64, num_workers=self.num_workers, shuffle=False, drop_last=False)\n",
    "        feats, labels, intermediate_features = [], [], {layer: [] for layer in self.intermediate_layers_to_capture}\n",
    "\n",
    "        for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "            batch_imgs = batch_imgs.to(self.device)\n",
    "            batch_feats = self.convnet(batch_imgs)\n",
    "            \n",
    "            feats.append(batch_feats.detach().cpu())\n",
    "            labels.append(batch_labels)\n",
    "            \n",
    "            # Collect intermediate layer outputs\n",
    "            for layer in self.intermediate_layers_to_capture:\n",
    "                # Final linear layer outputs a 2d tensor; but intermediate layers don't, so we flatten them (ready for PCA etc.)\n",
    "                layer_output_flattened = self.intermediate_layer_features[layer].view(self.intermediate_layer_features[layer].size(0), -1) \n",
    "                intermediate_features[layer].append(layer_output_flattened.cpu())\n",
    "        \n",
    "        # Concatenate results for each layer\n",
    "        feats = torch.cat(feats, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        intermediate_features = {layer: torch.cat(intermediate_features[layer], dim=0) for layer in self.intermediate_layers_to_capture}\n",
    "\n",
    "        return {**intermediate_features, 'final_layer': feats, 'labels': labels}\n",
    "\n",
    "intermediate_layers = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "sim_clr = SimCLR()\n",
    "sim_clr.load_pretrained()\n",
    "sim_clr.set_intermediate_layers_to_capture(intermediate_layers)\n",
    "feats = sim_clr.extract_features(image_dataset)\n",
    "\n",
    "layer1_feats = feats['layer1'] # Shape: torch.Size([1573, 200704]) (n_images, n_features)\n",
    "layer2_feats = feats['layer2']\n",
    "layer3_feats = feats['layer3']\n",
    "layer4_feats = feats['layer4']\n",
    "final_layer_feats = feats['final_layer'] # Shape: torch.Size([1573, 512])\n",
    "\n",
    "print('shape', layer1_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3. Apply PCA to SimCLR representations\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_components = 1500\n",
    "\n",
    "# TODO note: cross-validation, and subsampling of each layer, is done in notebooks/003_experiment_images/experiment_images.ipynb\n",
    "def run_pca(data, num_components=num_components):\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(data)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    return np.cumsum(explained_variance), explained_variance\n",
    "\n",
    "print(\"First 10 labels in SimCLR features:\", labels[:10])\n",
    "\n",
    "# Our original images are grayscale, but SimCLR expects 3-channel RGB input.\n",
    "# To meet this requirement, we duplicated the grayscale values across all three RGB channels.\n",
    "# However, for PCA, we only need a single channel, so we extract just the first channel (Red).\n",
    "flattened_images = images[:, 0, :, :].view(images.shape[0], -1) # shape: [1573, 50176] (1573 images, 224x224 pixels)\n",
    "\n",
    "cumulative_ev_raw, ev_raw = run_pca(flattened_images)\n",
    "cumulative_ev_layer2, ev_layer2 = run_pca(layer2_feats)\n",
    "cumulative_ev_layer4, ev_layer4 = run_pca(layer4_feats)\n",
    "cumulative_ev_final_layer, ev_final_layer = run_pca(final_layer_feats, 500)\n",
    "\n",
    "# Plot cumulative explained var vs. # principal components\n",
    "plot_components = range(1, num_components + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_components, cumulative_ev_raw, label=\"Raw Images\", marker='x')\n",
    "plt.plot(plot_components, cumulative_ev_layer2, label=\"SimCLR Layer 2\", marker='x')\n",
    "# plt.plot(plot_components, cumulative_ev_final_layer, label=\"SimCLR Final Layer\", marker='x')\n",
    "plt.xlabel(\"# Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA: Cumulative Explained Variance vs. Number of Components\")\n",
    "plt.legend()\n",
    "plt.text(\n",
    "    0.5, -0.15,  # X and Y coordinates\n",
    "    \"Note: The output of the base encoder's final linear layer is the recommended representation for downstream tasks (Chen et al., 2020).\",\n",
    "    fontsize=10,\n",
    "    color=\"gray\",\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    "    transform=plt.gca().transAxes\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.4. Choose principal components that explain a % of variance e.g. 90%.\n",
    "\n",
    "# Ensure the number of features is not vastly greater than the number of neurons, to reduce overfitting.\n",
    "# We have 5654 reliable neurons\n",
    "def get_num_components_for_variance(cumulative_variance, target_variance=0.9):\n",
    "    index_of_pc_reaching_target_var = np.argmax(cumulative_variance >= target_variance)\n",
    "    \n",
    "    if(index_of_pc_reaching_target_var == 0):\n",
    "        print(f\"Warning: The computed PCs do not cumulatively explain {target_variance * 100}% variance\")\n",
    "    \n",
    "    return index_of_pc_reaching_target_var + 1\n",
    "\n",
    "# Get the number of PCs for 90% variance\n",
    "num_pcs_raw = get_num_components_for_variance(cumulative_ev_raw, target_variance=0.75)\n",
    "num_pcs_layer2 = get_num_components_for_variance(cumulative_ev_layer2, target_variance=0.75)\n",
    "num_pcs_final_layer = get_num_components_for_variance(cumulative_ev_final_layer, target_variance=0.75)\n",
    "\n",
    "print(f\"Number of PCs explaining 90% variance (Raw Images): {num_pcs_raw}\")\n",
    "print(f\"Number of PCs explaining 90% variance (SimCLR Layer 2): {num_pcs_layer2}\")\n",
    "print(f\"Number of PCs explaining 90% variance (SimCLR Final Layer): {num_pcs_final_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.4. Project the data into PCA space\n",
    "\n",
    "# Our original images are grayscale, but SimCLR expects 3-channel RGB input.\n",
    "# To meet this requirement, we duplicated the grayscale values across all three RGB channels.\n",
    "# However, for PCA, we only need a single channel, so we extract just the first channel (Red).\n",
    "images.shape # shape: [1573, 3, 224, 224]\n",
    "flattened_images = images[:, 0, :, :].view(images.shape[0], -1) # shape: [1573, 50176] (1573 images, 224x224 pixels)\n",
    "\n",
    "# Use same number of principal components for each input\n",
    "num_pcs = min(num_pcs_raw, num_pcs_layer2, num_pcs_final_layer)\n",
    "\n",
    "## 3.4.1. For raw images\n",
    "pca_raw = PCA(n_components=num_pcs)\n",
    "pca_raw.fit(flattened_images)\n",
    "raw_image_pcs = pca_raw.transform(flattened_images) # Shape: (1573, N) -> 1573 images, N PCs\n",
    "\n",
    "## 3.4.2. For layer-2 activations\n",
    "pca_layer2 = PCA(n_components=num_pcs)\n",
    "pca_layer2.fit(layer2_feats)\n",
    "layer2_pcs = pca_layer2.transform(layer2_feats) # Shape: (1573, 1163) -> 1573 images, 1163 PCs\n",
    "\n",
    "## 3.4.3. For final layer activations\n",
    "pca_final_layer = PCA(n_components=num_pcs)\n",
    "pca_final_layer.fit(final_layer_feats)\n",
    "final_layer_pcs = pca_final_layer.transform(final_layer_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.1. Regression per neuron\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Gather the neural responses for the reliable neurons\n",
    "# we take the average across repeats for each neuron\n",
    "neural_responses = imresps[:, :, reliable_neuron_indices] # Shape: (1573, 2, 5654)\n",
    "neural_responses_mean = neural_responses.mean(axis=1) # Shape: (1573, 5654) -> 1573 images, 5654 neurons\n",
    "\n",
    "# Select a specific reliable neuron by index (because we will have a regression model per neuron)\n",
    "reliable_neuron_index = reliable_neuron_indices[0]\n",
    "mean_response_single_neuron = neural_responses_mean[:, reliable_neuron_index]  # Shape: (1573,)\n",
    "\n",
    "## 4.1.1. For raw images\n",
    "\n",
    "print('Raw image PCs shape', raw_image_pcs.shape) # (1573, 526)\n",
    "print('Mean response single neuron shape', mean_response_single_neuron.shape) # (1573,)\n",
    "\n",
    "# Fit a single linear regression model (handles all neurons at once)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    raw_image_pcs, neural_responses_mean, test_size=0.2, random_state=42\n",
    ")\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "raw_image_r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "\n",
    "for neuron_index, score in zip(reliable_neuron_indices[:10], raw_image_r2_scores):\n",
    "    print(f\"Raw Images: R^2 Score for Reliable Neuron {neuron_index}: {score}\")\n",
    "\n",
    "## 4.1.2. For SimCLR layer 2 features\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    layer2_pcs, neural_responses_mean, test_size=0.2, random_state=42\n",
    ")\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "layer_2_r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "\n",
    "for neuron_index, score in zip(reliable_neuron_indices[:10], layer_2_r2_scores):\n",
    "    print(f\"Layer 2: R^2 Score for Reliable Neuron {neuron_index}: {score}\")\n",
    "\n",
    "## 4.1.3. For SimCLR final layer features\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    final_layer_pcs, neural_responses_mean, test_size=0.2, random_state=42\n",
    ")\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "final_layer_r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "\n",
    "for neuron_index, score in zip(reliable_neuron_indices[:10], final_layer_r2_scores):\n",
    "    print(f\"Final Layer: R^2 Score for Reliable Neuron {neuron_index}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.1. Ridge regression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# TODO: tune reg param for Ridge\n",
    "# TODO: max val score by iterating alpha and test on test set\n",
    "\n",
    "## 5.1.1. For raw images\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_image_pcs, neural_responses_mean, test_size=0.2, random_state=42)\n",
    "reg = Ridge(alpha=1.0)\n",
    "reg.fit(X_train, y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "raw_images_r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "\n",
    "for neuron_index, score in zip(reliable_neuron_indices[:10], final_layer_r2_scores):\n",
    "    print(f\"Raw Images (Ridge): R^2 Score for Reliable Neuron {neuron_index}: {score}\")\n",
    "\n",
    "## 5.1.2. For SimCLR layer 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(layer2_pcs, neural_responses_mean, test_size=0.2, random_state=42)\n",
    "reg = Ridge(alpha=1.0)\n",
    "reg.fit(X_train, y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "layer_2_r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "\n",
    "for neuron_index, score in zip(reliable_neuron_indices[:10], final_layer_r2_scores):\n",
    "    print(f\"Layer 2 (Ridge): R^2 Score for Reliable Neuron {neuron_index}: {score}\")\n",
    "\n",
    "## 5.1.3. For SimCLR final layer\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_layer_pcs, neural_responses_mean, test_size=0.2, random_state=42)\n",
    "reg = Ridge(alpha=1.0)\n",
    "reg.fit(X_train, y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "final_layer_r2_scores = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "\n",
    "for neuron_index, score in zip(reliable_neuron_indices[:10], final_layer_r2_scores):\n",
    "    print(f\"Final Layer (Ridge): R^2 Score for Reliable Neuron {neuron_index}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "## Visualise the principal components (project the image into PC space)\n",
    "print('PC shape:', pca_raw.components_.shape) # (32, 50176)\n",
    "print('images shape:', images.shape) # (1573, 3, 224, 224)\n",
    "\n",
    "# Visualize the first 5 PCs as images\n",
    "for i in range(5):\n",
    "    pc_image = pca_raw.components_[i].reshape(images.shape[2], images.shape[3])  # Reshape to image dimensions\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(pc_image, cmap=\"gray\")\n",
    "    plt.title(f\"Principal Component {i+1}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# raw_image_pcs[i, j] → The score of the i-th image for the j-th principal component\n",
    "# e.g. how much image i is represented by a PC \n",
    "# e.g. if a PC captures \"vertical edges\", an image with strong vertical edges will have a high score for that component\n",
    "print(raw_image_pcs[0, 0])\n",
    "\n",
    "# Compute correlation between each PC and neural responses\n",
    "pc_index = 0  # Change this to test different PCs\n",
    "correlations = np.corrcoef(raw_image_pcs[:, pc_index], neural_responses_mean, rowvar=False)[0, 1:]\n",
    "\n",
    "# Plot histogram of correlations\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(correlations, bins=30, kde=True)\n",
    "plt.xlabel(f\"Raw Images: Correlation between PC {pc_index+1} and neural responses\")\n",
    "plt.ylabel(\"Number of neurons\")\n",
    "plt.title(f\"Histogram of PC {pc_index+1} correlation with neurons\")\n",
    "plt.show()\n",
    "\n",
    "# Identify top 5 neurons most correlated with the first PC\n",
    "top_neurons = np.argsort(np.abs(correlations))[-5:]\n",
    "\n",
    "# Scatter plot for each top neuron\n",
    "for neuron_id in top_neurons:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(raw_image_pcs[:, 0], neural_responses_mean[:, neuron_id], alpha=0.5)\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(raw_image_pcs[:, 0], neural_responses_mean[:, neuron_id])\n",
    "    plt.plot(raw_image_pcs[:, 0], slope * raw_image_pcs[:, 0] + intercept, color=\"red\", label=f\"R={r_value:.2f}\")\n",
    "    plt.xlabel(\"PC 1 Score\")\n",
    "    plt.ylabel(f\"Neuron {neuron_id} Response\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Neuron {neuron_id}: PC 1 vs Neural Response\")\n",
    "    plt.show()\n",
    "\n",
    "pc_index = 0  # Change this to test different PCs\n",
    "correlations = np.corrcoef(layer2_pcs[:, pc_index], neural_responses_mean, rowvar=False)[0, 1:]\n",
    "\n",
    "# Plot histogram of correlations\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(correlations, bins=30, kde=True)\n",
    "plt.xlabel(f\"Layer 2: Correlation between PC {pc_index+1} and neural responses\")\n",
    "plt.ylabel(\"Number of neurons\")\n",
    "plt.title(f\"Histogram of PC {pc_index+1} correlation with neurons\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for each top neuron\n",
    "for neuron_id in top_neurons:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(layer2_pcs[:, 0], neural_responses_mean[:, neuron_id], alpha=0.5)\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(layer2_pcs[:, 0], neural_responses_mean[:, neuron_id])\n",
    "    plt.plot(layer2_pcs[:, 0], slope * layer2_pcs[:, 0] + intercept, color=\"red\", label=f\"R={r_value:.2f}\")\n",
    "    plt.xlabel(\"PC 1 Score\")\n",
    "    plt.ylabel(f\"Neuron {neuron_id} Response\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Neuron {neuron_id}: PC 1 vs Neural Response\")\n",
    "    plt.show()\n",
    "\n",
    "pc_index = 0  # Change this to test different PCs\n",
    "correlations = np.corrcoef(final_layer_feats[:, pc_index], neural_responses_mean, rowvar=False)[0, 1:]\n",
    "\n",
    "# Plot histogram of correlations\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(correlations, bins=30, kde=True)\n",
    "plt.xlabel(f\"Final Layer: Correlation between PC {pc_index+1} and neural responses\")\n",
    "plt.ylabel(\"Number of neurons\")\n",
    "plt.title(f\"Histogram of PC {pc_index+1} correlation with neurons\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
