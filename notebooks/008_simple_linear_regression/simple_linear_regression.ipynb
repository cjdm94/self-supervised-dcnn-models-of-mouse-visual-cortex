{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis steps\n",
    "\n",
    "# 1. For each neuron, calculate variance explained by the stimulus across repeats. Plot the SRV distribution for all neurons.\n",
    "\n",
    "# 2. Shuffle responses (e.g., 100 random trials) to compute a baseline SRV. \n",
    "\n",
    "# 3. Keep neurons whose SRV is in the top 90th percentile of the shuffle distribution.\n",
    "\n",
    "# 4. Apply PCA to SimCLR representations and/or raw image data\n",
    "\n",
    "# 5. Choose a subset of principal components that explain a large proportion of the variance.\n",
    "\n",
    "# 6. Ensure the number of features is not vastly greater than the number of neurons to reduce overfitting.\n",
    "\n",
    "# 7. 80% training, 10% validation, 10% testing\n",
    "\n",
    "# 8. Training: Learn weights for regression\n",
    "\n",
    "# 9. Validation: Optimize the regularization parameter\n",
    "\n",
    "# 10. Testing: Evaluate the final model\n",
    "\n",
    "# 11. Predict the response of each neuron using SimCLR features as input.\n",
    "\n",
    "# 12. Train one model per neuron (Input: SimCLR features (e.g., 512 features for final layer; Output: Neural response (scalar value for that neuron))\n",
    "\n",
    "# 13. Aggregate results to evaluate overall prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "# imresps.npy is of shape (1573, 2, 15363), where 1573 is number of images, 2 repeats each, and 15363 neurons recorded\n",
    "# stimids.npy has the image id (matching the image dataset ~selection1866~) for each stimulus number, \n",
    "# so of you want to see what image was presented on imresps[502] you would check stim_ids[502]\n",
    "\n",
    "PATH_TO_DATA = '../../data/neural'\n",
    "\n",
    "imresps = np.load(path.join(PATH_TO_DATA, 'imresps.npy'))\n",
    "stimids = np.load(path.join(PATH_TO_DATA, 'stimids.npy'))\n",
    "\n",
    "print(imresps.shape) # (1573, 2, 15363)\n",
    "print(stimids.shape) # (1573,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signal_related_variance(resp_a, resp_b, mean_center=True):\n",
    "    \"\"\"\n",
    "    compute the fraction of signal-related variance for each neuron,\n",
    "    as per Stringer et al Nature 2019. Cross-validated by splitting\n",
    "    responses into two halves. Note, this only is \"correct\" if resp_a\n",
    "    and resp_b are *not* averages of many trials.\n",
    "\n",
    "    Args:\n",
    "        resp_a (ndarray): n_stimuli, n_cells\n",
    "        resp_b (ndarray): n_stimuli, n_cells\n",
    "\n",
    "    Returns:\n",
    "        fraction_of_stimulus_variance: 0-1, 0 is non-stimulus-caring, 1 is only-stimulus-caring neurons\n",
    "        stim_to_noise_ratio: ratio of the stim-related variance to all other variance\n",
    "    \"\"\"\n",
    "    if len(resp_a.shape) > 2:\n",
    "        # if the stimulus is multi-dimensional, flatten across all stimuli\n",
    "        resp_a = resp_a.reshape(-1, resp_a.shape[-1])\n",
    "        resp_b = resp_b.reshape(-1, resp_b.shape[-1])\n",
    "    ns, nc = resp_a.shape\n",
    "    if mean_center:\n",
    "        # mean-center the activity of each cell\n",
    "        resp_a = resp_a - resp_a.mean(axis=0)\n",
    "        resp_b = resp_b - resp_b.mean(axis=0)\n",
    "\n",
    "    # compute the cross-trial stimulus covariance of each cell\n",
    "    # dot-product each cell's (n_stim, ) vector from one half\n",
    "    # with its own (n_stim, ) vector on the other half\n",
    "\n",
    "    covariance = (resp_a * resp_b).sum(axis=0) / ns\n",
    "\n",
    "    # compute the variance of each cell across both halves\n",
    "    resp_a_variance = (resp_a**2).sum(axis=0) / ns\n",
    "    resp_b_variance = (resp_b**2).sum(axis=0) / ns\n",
    "    total_variance = (resp_a_variance + resp_b_variance) / 2\n",
    "\n",
    "    # compute the fraction of the total variance that is\n",
    "    # captured in the covariance\n",
    "    fraction_of_stimulus_variance = covariance / total_variance\n",
    "\n",
    "    # if you want, you can compute SNR as well:\n",
    "    stim_to_noise_ratio = fraction_of_stimulus_variance / (\n",
    "        1 - fraction_of_stimulus_variance\n",
    "    )\n",
    "\n",
    "    return fraction_of_stimulus_variance, stim_to_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter neurons based on SRV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. First compute the real SRV for each neuron\n",
    "\n",
    "# for each stimulus, randomly assign each repeat to spilt a or split b\n",
    "split_A, split_B = [], []\n",
    "for responses in imresps:\n",
    "    indices = np.random.permutation(2)\n",
    "    split_A.append(responses[indices[0]])\n",
    "    split_B.append(responses[indices[1]])\n",
    "\n",
    "split_A = np.vstack(split_A)\n",
    "split_B = np.vstack(split_B)\n",
    "\n",
    "real_srv_all_neurons, stim_to_noise_ratio = compute_signal_related_variance(split_A, split_B)\n",
    "print(real_srv_all_neurons)\n",
    "\n",
    "print('Image responses:', imresps.shape) # (1573, 2, 15363)\n",
    "print('Image responses split A:', split_A.shape) # (1573, 15363)\n",
    "print('Image responses split B:', split_B.shape) # (1573, 15363)\n",
    "print('SRV:', real_srv_all_neurons.shape) # (15363,)\n",
    "print('SNR:', stim_to_noise_ratio.shape) # (15363,)\n",
    "\n",
    "# Plot SRV distribution\n",
    "plt.hist(real_srv_all_neurons, bins=50, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Neurons\")\n",
    "plt.title(\"Real SRV: SRV Across Neurons\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Compute null distribution of SRV values for all neurons\n",
    "# Image responses: (1573, 2, 15363)\n",
    "num_stimuli = imresps.shape[0] # 1573\n",
    "num_repeats = imresps.shape[1] # 2\n",
    "num_neurons = imresps.shape[2] # 15363\n",
    "n_shuffles = 100\n",
    "\n",
    "# shape (n_shuffles, num_neurons)\n",
    "null_srv_all_neurons = []\n",
    "\n",
    "for _ in range(n_shuffles):\n",
    "    # Shuffle stimulus indices\n",
    "    shuffled_indices = np.random.permutation(num_stimuli)\n",
    "    shuffled_resps = imresps[shuffled_indices, :, :]  # Shuffle stimulus order\n",
    "\n",
    "    # Split into two groups, maintaining random assignments across stimuli\n",
    "    split_A = shuffled_resps[:, 0, :] # First repeat of shuffled stimuli\n",
    "    split_B = shuffled_resps[:, 1, :] # Second repeat of shuffled stimuli\n",
    "\n",
    "    # Compute SRV for the shuffled data - returns SRV for each neuron - shape (15363,)\n",
    "    fraction_of_stimulus_variance, _ = compute_signal_related_variance(split_A, split_B)\n",
    "    null_srv_all_neurons.append(fraction_of_stimulus_variance)\n",
    "\n",
    "# Convert null distribution to numpy array for easier indexing\n",
    "# shape (n_shuffles, num_neurons) - (100, 15363) - each value is the SRV for a neuron in a shuffle\n",
    "null_srv_all_neurons = np.array(null_srv_all_neurons)\n",
    "print(null_srv_all_neurons.shape)\n",
    "\n",
    "# e.g. if neuron_index = 0, it will plot the SRV value for neuron 0 across all shuffles\n",
    "neuron_index = 0\n",
    "plt.hist([srv[neuron_index] for srv in null_srv_all_neurons], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Now filter our neurons whose real SRV is in the top 90th percentile of its null distribution\n",
    "\n",
    "top_90th_percentile_null = np.percentile(null_srv_all_neurons, 90, axis=0)\n",
    "\n",
    "# reliable_neurons contains the indices of neurons whose real SRV is statistically significant\n",
    "reliable_neurons = np.where(real_srv_all_neurons >= top_90th_percentile_null)[0]\n",
    "print('Filtered neurons in top 90th percentile of null distribution:', len(reliable_neurons))\n",
    "print(reliable_neurons)\n",
    "\n",
    "# Just check that the real SRV is greater than the null 90th percentile for all reliable neurons\n",
    "for neuron in reliable_neurons:\n",
    "    real_srv = real_srv_all_neurons[neuron]\n",
    "    null_90th = top_90th_percentile_null[neuron]\n",
    "    print(f\"Neuron {neuron}: Real SRV = {real_srv}, Null 90th Percentile = {null_90th}\")\n",
    "    assert real_srv >= null_90th, f\"Neuron {neuron} failed the check!\"\n",
    "\n",
    "# Plot for the first 5 reliable neurons\n",
    "for neuron in reliable_neurons[:5]:\n",
    "    plt.hist(null_srv_all_neurons[:, neuron], bins=100, color='blue', alpha=0.7, label='Null Distribution')\n",
    "    plt.axvline(real_srv_all_neurons[neuron], color='red', linestyle='dashed', linewidth=2, label='Real SRV')\n",
    "    plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "    plt.ylabel(\"Number of Shuffles\")\n",
    "    plt.title(f\"Neuron {neuron}: Real SRV vs Null Distribution\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The SRV values are looking strange, need to sanity check the logic\n",
    "\n",
    "# Null SRV shape: (100, 15363) - good\n",
    "print(\"Null SRV shape:\", null_srv_all_neurons.shape)\n",
    "\n",
    "# Here the SRV values are all the same across all shuffles for the neuron, which is weird\n",
    "# Null SRV for neuron 12: [0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232 0.00635232 0.00635232\n",
    "#  0.00635232 0.00635232 0.00635232 0.00635232]\n",
    "print(\"Null SRV for neuron 12:\", null_srv_all_neurons[:, 12])\n",
    "\n",
    "# Is shuffling logic correct? Indices should be different for each shuffle - looks correct\n",
    "# Shuffle 0 indices (first 10): [ 240   85 1260  177  940  994  718  528  186  194]\n",
    "# Shuffle 1 indices (first 10): [1038  925  615  186  938  793  558  454 1409  771]\n",
    "# Shuffle 2 indices (first 10): [ 964  963  198  307   26 1055 1500  151  909 1486]\n",
    "# Shuffle 3 indices (first 10): [1086 1040  964 1403 1093  175  340  262  773  783]\n",
    "# Shuffle 4 indices (first 10): [ 637  230  958  787  392 1564  469  156 1407 1479]\n",
    "for i in range(5):\n",
    "    shuffled_indices = np.random.permutation(num_stimuli)\n",
    "    print(f\"Shuffle {i} indices (first 10): {shuffled_indices[:10]}\")\n",
    "\n",
    "shuffled_indices = np.random.permutation(num_stimuli)\n",
    "shuffled_resps = imresps[shuffled_indices, :, :]\n",
    "\n",
    "split_A = shuffled_resps[:, 0, :]  # First repeat\n",
    "split_B = shuffled_resps[:, 1, :]  # Second repeat\n",
    "\n",
    "# The two splits do seem to have unique values - looks correct\n",
    "# Split B (first 5 neurons, first 5 stimuli): [[0.         0.6505735  0.05245936 0.2740306  0.10461244]\n",
    "#  [0.01191196 0.         0.         0.         0.69875743]\n",
    "#  [0.0321094  0.053065   0.63204853 0.09543178 0.81210066]\n",
    "#  [0.68243115 0.         1.5167197  0.11282894 0.23435783]\n",
    "#  [0.         0.09517568 0.00289441 0.42277867 0.24733859]]\n",
    "# Split A (first 5 neurons, first 5 stimuli): [[1.02488546 0.1708228  0.38181075 0.5764056  0.08896205]\n",
    "#  [1.94878199 1.01675761 1.0019273  0.22494237 0.        ]\n",
    "#  [0.07141742 0.00980155 0.         0.63551881 0.39534339]\n",
    "#  [0.77388581 0.31061662 1.48310569 0.19047658 0.        ]\n",
    "#  [0.         0.68964413 0.         0.36437469 0.30127275]]\n",
    "print(\"Split B (first 5 neurons, first 5 stimuli):\", split_B[:5, :5])\n",
    "print(\"Split A (first 5 neurons, first 5 stimuli):\", split_A[:5, :5])\n",
    "\n",
    "shuffled_indices = np.random.permutation(num_stimuli)\n",
    "shuffled_resps = imresps[shuffled_indices, :, :]\n",
    "\n",
    "split_A = shuffled_resps[:, 0, :]\n",
    "split_B = shuffled_resps[:, 1, :]\n",
    "\n",
    "# These values look strange - SRV values for shuffled data are negative or very close to zero\n",
    "# [-0.02816453 -0.00743509 -0.03484814  0.00073648 -0.02779006  0.00868213 -0.01656676 -0.00235512 -0.05268748 -0.03571497]\n",
    "test_srv, _ = compute_signal_related_variance(split_A, split_B)\n",
    "print(\"Test SRV (first 10 neurons):\", test_srv[:10])\n",
    "\n",
    "# Let's test the compute_signal_related_variance function with some dummy data\n",
    "split_A_test = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # Shape (3, 3)\n",
    "split_B_test = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # Identical to split_A\n",
    "\n",
    "# This does look correct, but there is a warning\n",
    "# Test SRV (synthetic data): [1. 1. 1.]\n",
    "# RuntimeWarning: divide by zero encountered in divide\n",
    "  # stim_to_noise_ratio = fraction_of_stimulus_variance / (\n",
    "test_srv, _ = compute_signal_related_variance(split_A_test, split_B_test)\n",
    "print(\"Test SRV (synthetic data):\", test_srv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
