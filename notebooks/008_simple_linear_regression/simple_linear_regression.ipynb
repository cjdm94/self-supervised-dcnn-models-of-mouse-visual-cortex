{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis steps\n",
    "\n",
    "# 1. For each neuron, calculate variance explained by the stimulus across repeats. Plot the SRV distribution for all neurons.\n",
    "\n",
    "# 2. Shuffle responses (e.g., 100 random trials) to compute a baseline SRV. \n",
    "\n",
    "# 3. Keep neurons whose SRV is in the top 90th percentile of the shuffle distribution.\n",
    "\n",
    "# 4. Apply PCA to SimCLR representations and/or raw image data\n",
    "\n",
    "# 5. Choose a subset of principal components that explain a large proportion of the variance.\n",
    "\n",
    "# 6. Ensure the number of features is not vastly greater than the number of neurons to reduce overfitting.\n",
    "\n",
    "# 7. 80% training, 10% validation, 10% testing\n",
    "\n",
    "# 8. Training: Learn weights for regression\n",
    "\n",
    "# 9. Validation: Optimize the regularization parameter\n",
    "\n",
    "# 10. Testing: Evaluate the final model\n",
    "\n",
    "# 11. Predict the response of each neuron using SimCLR features as input.\n",
    "\n",
    "# 12. Train one model per neuron (Input: SimCLR features (e.g., 512 features for final layer; Output: Neural response (scalar value for that neuron))\n",
    "\n",
    "# 13. Aggregate results to evaluate overall prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "# imresps.npy is of shape (1573, 2, 15363), where 1573 is number of images, 2 repeats each, and 15363 neurons recorded\n",
    "# stimids.npy has the image id (matching the image dataset ~selection1866~) for each stimulus number, \n",
    "# so of you want to see what image was presented on imresps[502] you would check stim_ids[502]\n",
    "\n",
    "PATH_TO_DATA = '../../data/neural'\n",
    "\n",
    "imresps = np.load(path.join(PATH_TO_DATA, 'imresps.npy'))\n",
    "stimids = np.load(path.join(PATH_TO_DATA, 'stimids.npy'))\n",
    "\n",
    "print(imresps.shape) # (1573, 2, 15363)\n",
    "print(stimids.shape) # (1573,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signal_related_variance(resp_a, resp_b, mean_center=True):\n",
    "    \"\"\"\n",
    "    compute the fraction of signal-related variance for each neuron,\n",
    "    as per Stringer et al Nature 2019. Cross-validated by splitting\n",
    "    responses into two halves. Note, this only is \"correct\" if resp_a\n",
    "    and resp_b are *not* averages of many trials.\n",
    "\n",
    "    Args:\n",
    "        resp_a (ndarray): n_stimuli, n_cells\n",
    "        resp_b (ndarray): n_stimuli, n_cells\n",
    "\n",
    "    Returns:\n",
    "        fraction_of_stimulus_variance: 0-1, 0 is non-stimulus-caring, 1 is only-stimulus-caring neurons\n",
    "        stim_to_noise_ratio: ratio of the stim-related variance to all other variance\n",
    "    \"\"\"\n",
    "    if len(resp_a.shape) > 2:\n",
    "        # if the stimulus is multi-dimensional, flatten across all stimuli\n",
    "        resp_a = resp_a.reshape(-1, resp_a.shape[-1])\n",
    "        resp_b = resp_b.reshape(-1, resp_b.shape[-1])\n",
    "    ns, nc = resp_a.shape\n",
    "    if mean_center:\n",
    "        # mean-center the activity of each cell\n",
    "        resp_a = resp_a - resp_a.mean(axis=0)\n",
    "        resp_b = resp_b - resp_b.mean(axis=0)\n",
    "\n",
    "    # compute the cross-trial stimulus covariance of each cell\n",
    "    # dot-product each cell's (n_stim, ) vector from one half\n",
    "    # with its own (n_stim, ) vector on the other half\n",
    "\n",
    "    covariance = (resp_a * resp_b).sum(axis=0) / ns\n",
    "\n",
    "    # compute the variance of each cell across both halves\n",
    "    resp_a_variance = (resp_a**2).sum(axis=0) / ns\n",
    "    resp_b_variance = (resp_b**2).sum(axis=0) / ns\n",
    "    total_variance = (resp_a_variance + resp_b_variance) / 2\n",
    "\n",
    "    # compute the fraction of the total variance that is\n",
    "    # captured in the covariance\n",
    "    fraction_of_stimulus_variance = covariance / total_variance\n",
    "\n",
    "    # if you want, you can compute SNR as well:\n",
    "    stim_to_noise_ratio = fraction_of_stimulus_variance / (\n",
    "        1 - fraction_of_stimulus_variance\n",
    "    )\n",
    "\n",
    "    return fraction_of_stimulus_variance, stim_to_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute SRV and filter most reliable neurons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for each stimulus, randomly assign each repeat to spilt a or split b\n",
    "split_A, split_B = [], []\n",
    "for responses in imresps:\n",
    "    indices = np.random.permutation(2)\n",
    "    split_A.append(responses[indices[0]])\n",
    "    split_B.append(responses[indices[1]])\n",
    "\n",
    "split_A = np.vstack(split_A)\n",
    "split_B = np.vstack(split_B)\n",
    "\n",
    "fraction_of_stimulus_variance, stim_to_noise_ratio = compute_signal_related_variance(split_A, split_B)\n",
    "print(fraction_of_stimulus_variance)\n",
    "\n",
    "print('Image responses:', imresps.shape) # (1573, 2, 15363)\n",
    "print('Image responses split A:', split_A.shape) # (1573, 15363)\n",
    "print('Image responses split B:', split_B.shape) # (1573, 15363)\n",
    "print('SRV:', fraction_of_stimulus_variance.shape) # (15363,)\n",
    "print('SNR:', stim_to_noise_ratio.shape) # (15363,)\n",
    "\n",
    "# Plot SRV distribution\n",
    "plt.hist(fraction_of_stimulus_variance, bins=50, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Neurons\")\n",
    "plt.title(\"Distribution of SRV Across Neurons\")\n",
    "plt.show()\n",
    "\n",
    "# Filter out neurons in the top 90th percentile (maintaining the indices)\n",
    "top_90th_percentile = np.percentile(fraction_of_stimulus_variance, 90)\n",
    "\n",
    "# The output is an array of indices corresponding to the positions of these reliable neurons \n",
    "# in the original fraction_of_stimulus_variance array. It preserves the link to the original \n",
    "# data because it gives you the positions of the reliable neurons relative to the full list of neurons.\n",
    "reliable_neurons = np.where(fraction_of_stimulus_variance >= top_90th_percentile)[0]\n",
    "\n",
    "print('Filtered neurons in top 90th percentile:', len(reliable_neurons)) # 1537\n",
    "\n",
    "srv_reliable = fraction_of_stimulus_variance[reliable_neurons]\n",
    "plt.hist(srv_reliable, bins=50, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Neurons\")\n",
    "plt.title(\"Distribution of SRV Across Reliable (>90th percentile) Neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute a null distribution of SRV values\n",
    "\n",
    "# Image responses: (1573, 2, 15363)\n",
    "num_stimuli = imresps.shape[0] # 1573\n",
    "num_repeats = imresps.shape[1] # 2\n",
    "num_neurons = imresps.shape[2] # 15363\n",
    "n_shuffles = 100\n",
    "srv_null_distribution = []\n",
    "\n",
    "# TODO: use full shuffling of stimuli rather than just shuffling repeats\n",
    "for _ in range(n_shuffles):\n",
    "    split_A, split_B = [], []\n",
    "    for responses in imresps:\n",
    "        indices = np.random.permutation(2)  # Randomly permute repeats\n",
    "        split_A.append(responses[indices[0]])\n",
    "        split_B.append(responses[indices[1]])\n",
    "\n",
    "    split_A = np.vstack(split_A)\n",
    "    split_B = np.vstack(split_B)\n",
    "\n",
    "    # Compute SRV for the shuffled data\n",
    "    fraction_of_stimulus_variance, _ = compute_signal_related_variance(split_A, split_B)\n",
    "    srv_null_distribution.append(fraction_of_stimulus_variance)\n",
    "\n",
    "# Plot the null distribution for a SINGLE SHUFFLE for a SINGLE NEURON\n",
    "plt.hist(srv_null_distribution[0], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(\"Null Distribution of SRV Across Shuffles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute null distribution for all neurons, and plot for a single neuron\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. First compute the real SRV for each neuron\n",
    "\n",
    "# for each stimulus, randomly assign each repeat to spilt a or split b\n",
    "split_A, split_B = [], []\n",
    "for responses in imresps:\n",
    "    indices = np.random.permutation(2)\n",
    "    split_A.append(responses[indices[0]])\n",
    "    split_B.append(responses[indices[1]])\n",
    "\n",
    "split_A = np.vstack(split_A)\n",
    "split_B = np.vstack(split_B)\n",
    "\n",
    "real_srv_all_neurons, stim_to_noise_ratio = compute_signal_related_variance(split_A, split_B)\n",
    "print(real_srv_all_neurons)\n",
    "\n",
    "print('Image responses:', imresps.shape) # (1573, 2, 15363)\n",
    "print('Image responses split A:', split_A.shape) # (1573, 15363)\n",
    "print('Image responses split B:', split_B.shape) # (1573, 15363)\n",
    "print('SRV:', real_srv_all_neurons.shape) # (15363,)\n",
    "print('SNR:', stim_to_noise_ratio.shape) # (15363,)\n",
    "\n",
    "# Plot SRV distribution\n",
    "plt.hist(real_srv_all_neurons, bins=50, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Neurons\")\n",
    "plt.title(\"Real SRV: SRV Across Neurons\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Compute null distribution of SRV values for all neurons\n",
    "# Image responses: (1573, 2, 15363)\n",
    "num_stimuli = imresps.shape[0] # 1573\n",
    "num_repeats = imresps.shape[1] # 2\n",
    "num_neurons = imresps.shape[2] # 15363\n",
    "n_shuffles = 100\n",
    "\n",
    "# shape (n_shuffles, num_neurons)\n",
    "null_srv_all_neurons = []\n",
    "\n",
    "for _ in range(n_shuffles):\n",
    "    # Shuffle stimulus indices\n",
    "    shuffled_indices = np.random.permutation(num_stimuli)\n",
    "    shuffled_resps = imresps[shuffled_indices, :, :]  # Shuffle stimulus order\n",
    "\n",
    "    # Split into two groups, maintaining random assignments across stimuli\n",
    "    split_A = shuffled_resps[:, 0, :] # First repeat of shuffled stimuli\n",
    "    split_B = shuffled_resps[:, 1, :] # Second repeat of shuffled stimuli\n",
    "\n",
    "    # Compute SRV for the shuffled data - returns SRV for each neuron - shape (15363,)\n",
    "    fraction_of_stimulus_variance, _ = compute_signal_related_variance(split_A, split_B)\n",
    "    null_srv_all_neurons.append(fraction_of_stimulus_variance)\n",
    "\n",
    "# Convert null distribution to numpy array for easier indexing\n",
    "# shape (n_shuffles, num_neurons) - (100, 15363) - each value is the SRV for a neuron in a shuffle\n",
    "null_srv_all_neurons = np.array(null_srv_all_neurons)\n",
    "print(null_srv_all_neurons.shape)\n",
    "\n",
    "# e.g. if neuron_index = 0, it will plot the SRV value for neuron 0 across all shuffles\n",
    "neuron_index = 0\n",
    "plt.hist([srv[neuron_index] for srv in null_srv_all_neurons], bins=100, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Fraction of Stimulus-Related Variance (SRV)\")\n",
    "plt.ylabel(\"Number of Shuffles\")\n",
    "plt.title(f\"Null Distribution of SRV for Neuron {neuron_index}\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Now filter our neurons whose real SRV is in the top 90th percentile of its null distribution\n",
    "\n",
    "top_90th_percentile_null = np.percentile(null_srv_all_neurons, 90, axis=0)\n",
    "\n",
    "# reliable_neurons contains the indices of neurons whose real SRV is statistically significant\n",
    "reliable_neurons = np.where(real_srv_all_neurons >= top_90th_percentile_null)[0]\n",
    "print('Filtered neurons in top 90th percentile of null distribution:', len(reliable_neurons))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
