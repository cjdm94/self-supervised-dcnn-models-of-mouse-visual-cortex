{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from Cadena et al. 2019\n",
    "# NOTE: they applied to their images, shown to the monkeys, a circular aperture mask with cosine fade-out\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('../../data/cadena_plosCB19/cadena_ploscb_data.pkl', 'rb') as g:\n",
    "    loaded_data = pickle.load(g)\n",
    "\n",
    "# Cadena found that the transfer‐learning approach (using VGG features) reached near-optimal performance with as little as 20% of the available data\n",
    "SAMPLE_SIZE = 1400\n",
    "rng = np.random.RandomState(42)\n",
    "SAMPLE_INDICES = np.random.choice(loaded_data[\"images\"].shape[0], SAMPLE_SIZE, replace=False)\n",
    "\n",
    "# Check the available keys and shapes\n",
    "for key, value in loaded_data.items():\n",
    "    print(f\"{key}: {value.shape if isinstance(value, np.ndarray) else type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess neural data\n",
    "\n",
    "responses = loaded_data[\"responses\"]\n",
    "print(\"Responses shape:\", responses.shape) # (4, 7250, 166) -> 4 repetitions, 7250 images, 166 neurons\n",
    "\n",
    "# Check how many images have no valid responses across all neurons and repetitions\n",
    "fully_missing_images = np.isnan(loaded_data[\"responses\"]).all(axis=(0, 2)) # Check over repetitions & neurons\n",
    "num_fully_missing = fully_missing_images.sum()\n",
    "print(f\"Fully missing images: {num_fully_missing}/{loaded_data['responses'].shape[1]}\")\n",
    "\n",
    "# Load neural responses and average over the 4 repetitions\n",
    "averaged_responses = np.nanmean(responses, axis=0) # Shape: (7250, 166)\n",
    "print(\"Averaged Responses shape:\", averaged_responses.shape)\n",
    "\n",
    "averaged_responses_cleaned = np.nan_to_num(averaged_responses) # Apply Cadena's preprocessing: Replace NaNs with 0\n",
    "print('Responses sample:', averaged_responses_cleaned[:20])\n",
    "\n",
    "# Select only the first 3625 samples, because we will only use half the images\n",
    "processed_neural_responses = averaged_responses_cleaned[SAMPLE_INDICES]\n",
    "print('Final responses shape:', processed_neural_responses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare images for VGG-19\n",
    "\n",
    "# import torchvision.transforms as transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "# # Define VGG-compatible transformation\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  \n",
    "#     transforms.Grayscale(num_output_channels=3), # Convert grayscale to 3 channels\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Apply transformation to all images (using half for now due to memory constraints)\n",
    "# sample = loaded_data[\"images\"][SAMPLE_INDICES]\n",
    "# images = np.stack([\n",
    "#     transform(Image.fromarray(img.astype(np.uint8))).numpy() for img in sample\n",
    "# ])\n",
    "\n",
    "# print(\"Transformed Images Shape:\", images.shape)  # (7250, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cadena's preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Assume you have a function that implements Cadena's preprocessing:\n",
    "def preprocess_image(img, global_avg_std):\n",
    "    # --- Contrast matching ---\n",
    "    h, w = img.shape  # raw image should be 140x140\n",
    "    patch_size = 70\n",
    "    start_row_patch = (h - patch_size) // 2\n",
    "    start_col_patch = (w - patch_size) // 2\n",
    "    central_patch = img[start_row_patch:start_row_patch+patch_size, start_col_patch:start_col_patch+patch_size]\n",
    "    current_mean = np.mean(central_patch)\n",
    "    current_std = np.std(central_patch)\n",
    "    if current_std == 0:\n",
    "        current_std = 1.0\n",
    "    matched_img = (img - current_mean) * (global_avg_std / current_std) + 128\n",
    "    matched_img = np.clip(matched_img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # --- Crop the central 80x80 region ---\n",
    "    crop_size = 80\n",
    "    start_row_crop = (h - crop_size) // 2\n",
    "    start_col_crop = (w - crop_size) // 2\n",
    "    cropped_img = matched_img[start_row_crop:start_row_crop+crop_size, start_col_crop:start_col_crop+crop_size]\n",
    "    \n",
    "    # --- Downsample the crop to 40x40 using bicubic interpolation ---\n",
    "    resized_img = cv2.resize(cropped_img, (40, 40), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # --- Z-score the image ---\n",
    "    mean_val = np.mean(resized_img)\n",
    "    std_val = np.std(resized_img)\n",
    "    if std_val == 0:\n",
    "        std_val = 1.0\n",
    "    zscored_img = (resized_img - mean_val) / std_val\n",
    "    return zscored_img\n",
    "\n",
    "def compute_global_avg_std(images):\n",
    "    patch_size = 70\n",
    "    stds = []\n",
    "    h, w = images[0].shape\n",
    "    start_row = (h - patch_size) // 2\n",
    "    start_col = (w - patch_size) // 2\n",
    "    for img in images:\n",
    "        central_patch = img[start_row:start_row+patch_size, start_col:start_col+patch_size]\n",
    "        stds.append(np.std(central_patch))\n",
    "    return np.mean(stds)\n",
    "\n",
    "# Suppose raw_images is your loaded array of shape (n_images, 140, 140)\n",
    "# Cadena found that the transfer‐learning approach (using VGG features) reached near-optimal performance with as little as 20% of the available data\n",
    "SAMPLE_SIZE = 1400\n",
    "rng = np.random.RandomState(42)\n",
    "SAMPLE_INDICES = np.random.choice(loaded_data[\"images\"].shape[0], SAMPLE_SIZE, replace=False)\n",
    "raw_images = loaded_data[\"images\"][SAMPLE_INDICES]\n",
    "global_avg_std = compute_global_avg_std(raw_images)\n",
    "\n",
    "# Apply the preprocessing to a subset (or all) of your images:\n",
    "preprocessed_images = np.array([preprocess_image(img, global_avg_std) for img in raw_images])\n",
    "print(\"Preprocessed images shape:\", preprocessed_images.shape)  # Expect (n, 40, 40)\n",
    "\n",
    "# Now, if your model expects 224x224 images, you can upsample:\n",
    "upsampled_images = np.array([cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC) for img in preprocessed_images])\n",
    "print(\"Upsampled images shape:\", upsampled_images.shape)  # (n, 224, 224)\n",
    "\n",
    "# Then convert to PIL images and apply the VGG-compatible transform:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # if needed, though upsampled_images are already grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transformed_images = np.stack([transform(Image.fromarray(img.astype(np.uint8))).numpy() for img in upsampled_images])\n",
    "print(\"Transformed Images Shape:\", transformed_images.shape)  # Should be (n, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "PATH_TO_FEATURES = \"../../data/cadena_plosCB19/vgg_features_preprocessed.npy\"\n",
    "\n",
    "if os.path.exists(PATH_TO_FEATURES):\n",
    "    print(f\"Features file '{PATH_TO_FEATURES}' exists. Loading features...\")\n",
    "else:\n",
    "    print(f\"Features file does not exist. Extracting features...\")\n",
    "    \n",
    "    # Define feature extractor (VGG-19 up to conv3_1)\n",
    "    class VGGFeatureExtractor(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(VGGFeatureExtractor, self).__init__()\n",
    "            # Extract feature maps (256, 56, 56) from conv3_1 layer (BEFORE max pooling)\n",
    "            self.features = torch.nn.Sequential(*list(models.vgg19(pretrained=True).features.children())[:14])\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.features(x)\n",
    "\n",
    "    # Device configuration (Use GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    feature_extractor = VGGFeatureExtractor().to(device).eval()\n",
    "\n",
    "    # Convert images to Torch tensor dataset\n",
    "    images_tensor = torch.tensor(transformed_images, dtype=torch.float32).to(device)  # Shape: (3625, 3, 224, 224)\n",
    "\n",
    "    # DataLoader for batch processing\n",
    "    batch_size = 8\n",
    "    dataset = TensorDataset(images_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Store all batches in memory\n",
    "    all_batches = []\n",
    "\n",
    "    # Extract features batch-wise and store in RAM\n",
    "    with torch.no_grad():  # Disable autograd for efficiency\n",
    "        for batch_idx, (batch,) in enumerate(dataloader):\n",
    "            batch = batch.to(device)  # Move batch to GPU (if available)\n",
    "            features = feature_extractor(batch).cpu().numpy()  # Move to CPU\n",
    "\n",
    "            all_batches.append(features)  # Store batch in memory\n",
    "\n",
    "            # Free memory\n",
    "            del batch, features\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print(f\"Processed batch {batch_idx + 1}/{len(dataloader)}\")\n",
    "\n",
    "    # Concatenate all batches into a single NumPy array\n",
    "    vgg_features = np.concatenate(all_batches, axis=0)\n",
    "    print(\"Final Features Shape:\", vgg_features.shape) # Expected: (3625, 256, 56, 56)\n",
    "    np.save(PATH_TO_FEATURES, vgg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load features from file (assumed shape: (1400, 256, 56, 56))\n",
    "PATH_TO_FEATURES = \"../../data/cadena_plosCB19/vgg_features_preprocessed.npy\"\n",
    "vgg_features = np.load(PATH_TO_FEATURES, mmap_mode=\"r\")\n",
    "# Flatten features: (1400, feature_dim)\n",
    "X = vgg_features.reshape(vgg_features.shape[0], -1)\n",
    "\n",
    "# processed_neural_responses: averaged responses for selected neurons (shape: (1400, 166))\n",
    "y = processed_neural_responses\n",
    "\n",
    "print(\"Final Shapes -> X:\", X.shape, \"y:\", y.shape)\n",
    "\n",
    "# --- Create train/validation/test splits while keeping track of indices ---\n",
    "n_total = y.shape[0]  # total number of images used (should be 1400)\n",
    "indices = np.arange(n_total)\n",
    "\n",
    "# First, split into train+val (80%) and test (20%)\n",
    "train_val_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train_val = X[train_val_idx]\n",
    "X_test = X[test_idx]\n",
    "Y_train_val = y[train_val_idx]\n",
    "Y_test = y[test_idx]\n",
    "\n",
    "# Then, split train+val into training (80% of 80% = 64% overall) and validation (16% overall)\n",
    "train_idx, val_idx = train_test_split(train_val_idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = X[train_idx]\n",
    "X_val = X[val_idx]\n",
    "Y_train = y[train_idx]\n",
    "Y_val = y[val_idx]\n",
    "\n",
    "print(\"Split Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"Y_train:\", Y_train.shape)\n",
    "print(\"  X_val  :\", X_val.shape,   \"Y_val  :\", Y_val.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \"Y_test :\", Y_test.shape)\n",
    "\n",
    "# --- Fit Ridge Regression ---\n",
    "alpha = 100000\n",
    "ridge_reg = Ridge(alpha=alpha)\n",
    "ridge_reg.fit(X_train, Y_train)\n",
    "y_pred = ridge_reg.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "print(f\"Test R² Score: {r2:.3f}\")\n",
    "\n",
    "# --- Compute FEV using trial-level responses ---\n",
    "# For FEV, we need the original (trial-level) responses corresponding to the images used.\n",
    "# Assume loaded_data[\"responses\"] has shape (n_reps, total_images, total_neurons)\n",
    "# and that processed_neural_responses was computed using the first 1400 images.\n",
    "all_responses = loaded_data[\"responses\"][:, :n_total, :]  # Restrict to the 1400 images used.\n",
    "# Also restrict to the top neurons (if not already done); assume processed_neural_responses has the correct neurons.\n",
    "all_responses_test = all_responses[:, test_idx, :]  # Now shape: (n_reps, n_test, 166)\n",
    "\n",
    "def compute_fev(y_true, y_pred, all_responses, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    y_true: Averaged neural responses, shape (n_samples, n_neurons)\n",
    "    y_pred: Model predictions, shape (n_samples, n_neurons)\n",
    "    all_responses: Trial-level responses for these images, shape (n_reps, n_samples, n_neurons)\n",
    "    \"\"\"\n",
    "    # Total variance over test images for each neuron (from the averaged responses)\n",
    "    total_variance = np.var(y_true, axis=0)\n",
    "    # Variance explained by the predictions (per neuron)\n",
    "    explained_variance = np.var(y_pred, axis=0)\n",
    "    # Noise variance: compute variance over repetitions for each image and neuron, then average over images.\n",
    "    noise_variance = np.nanmean(np.var(all_responses, axis=0), axis=0)\n",
    "    \n",
    "    fev_per_neuron = 1 - (total_variance - explained_variance) / (total_variance - noise_variance + epsilon)\n",
    "    return np.mean(fev_per_neuron)\n",
    "\n",
    "fev_score = compute_fev(Y_test, y_pred, all_responses_test)\n",
    "print(f\"Fraction of Explainable Variance (FEV): {fev_score:.3f}\")\n",
    "\n",
    "# --- Optionally, plot the regression performance ---\n",
    "pcs_values = [0, 10, 100, 1000]\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "test_r2_scores = []\n",
    "fev_scores = []\n",
    "\n",
    "# For demonstration, loop over different PCA dimensionalities (if desired)\n",
    "from sklearn.decomposition import PCA\n",
    "for num_pcs in pcs_values:\n",
    "    if num_pcs > 0:\n",
    "        pca = PCA(n_components=num_pcs, random_state=42)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_val_pca   = pca.transform(X_val)\n",
    "        X_test_pca  = pca.transform(X_test)\n",
    "    else:\n",
    "        X_train_pca = X_train\n",
    "        X_val_pca   = X_val\n",
    "        X_test_pca  = X_test\n",
    "    \n",
    "    reg = Ridge(alpha=alpha)\n",
    "    reg.fit(X_train_pca, Y_train)\n",
    "    \n",
    "    train_pred = reg.predict(X_train_pca)\n",
    "    val_pred   = reg.predict(X_val_pca)\n",
    "    test_pred  = reg.predict(X_test_pca)\n",
    "    \n",
    "    train_r2 = r2_score(Y_train, train_pred)\n",
    "    val_r2   = r2_score(Y_val, val_pred)\n",
    "    test_r2  = r2_score(Y_test, test_pred)\n",
    "    \n",
    "    train_r2_scores.append(train_r2)\n",
    "    val_r2_scores.append(val_r2)\n",
    "    test_r2_scores.append(test_r2)\n",
    "    \n",
    "    # Compute FEV on test set\n",
    "    # For this, we assume that the same test indices (test_idx) apply to the original responses.\n",
    "    fev_val = compute_fev(Y_test, test_pred, all_responses_test)\n",
    "    fev_scores.append(fev_val)\n",
    "    \n",
    "    print(f\"PCs: {num_pcs}, Train R²: {train_r2:.4f}, Val R²: {val_r2:.4f}, Test R²: {test_r2:.4f}, Test FEV: {fev_val:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(pcs_values, train_r2_scores, marker='o', linestyle='--', label='Train R²')\n",
    "plt.plot(pcs_values, val_r2_scores, marker='s', linestyle='-', label='Validation R²')\n",
    "plt.plot(pcs_values, test_r2_scores, marker='^', linestyle='-', label='Test R²')\n",
    "plt.plot(pcs_values, fev_scores, marker='d', linestyle='-', label='Test FEV')\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(f\"Ridge Regression from {image_representation_name} to Neural Responses\")\n",
    "plt.legend()\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Poisson regression model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "vgg_features = np.load(PATH_TO_FEATURES, mmap_mode=\"r\") # Use mmap_mode for large files\n",
    "\n",
    "# X: (3625, num_features) and y: (3625, 166)\n",
    "X = vgg_features.reshape(vgg_features.shape[0], -1) # Flatten from (3625, 256, 56, 56) (3625, feature_dimensions)\n",
    "y = processed_neural_responses\n",
    "print(\"Final Shapes -> X:\", X.shape, \"y:\", processed_neural_responses.shape)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_neurons = y_train.shape[1]\n",
    "models = []\n",
    "y_pred_test_all = np.zeros_like(y_test)\n",
    "r2_list = []\n",
    "\n",
    "# Loop over each neuron (output dimension)\n",
    "for i in range(1):\n",
    "    # Fit a separate PoissonRegressor for neuron i\n",
    "    model = PoissonRegressor(alpha=0.01, max_iter=1000)\n",
    "    model.fit(X_train, y_train[:, i])\n",
    "    models.append(model)\n",
    "    \n",
    "    # Predict on the test set for this neuron\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_test_all[:, i] = y_pred\n",
    "    \n",
    "    # Compute R² for this neuron and store it\n",
    "    r2 = r2_score(y_test[:, i], y_pred)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "# Compute mean R² across neurons\n",
    "mean_r2 = np.mean(r2_list)\n",
    "print(f\"Mean Test R² Score: {mean_r2:.3f}\")\n",
    "\n",
    "# Optionally, define the FEV function and compute average FEV\n",
    "def compute_fev(y_true, y_pred):\n",
    "    # Compute noise variance, total variance, and explained variance for each neuron\n",
    "    noise_variance = np.var(y_true - np.mean(y_true, axis=0), axis=0)\n",
    "    total_variance = np.var(y_true, axis=0)\n",
    "    explained_variance = np.var(y_pred, axis=0)\n",
    "    fev = 1 - (total_variance - explained_variance) / (total_variance - noise_variance)\n",
    "    return np.mean(fev)\n",
    "\n",
    "fev_score = compute_fev(y_test, y_pred_test_all)\n",
    "print(f\"Mean Fraction of Explainable Variance (FEV): {fev_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
